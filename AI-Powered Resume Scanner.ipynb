{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4986e8ef78544750b134788e08d9acec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18b07484bd6a4837bb73f9823d471997",
              "IPY_MODEL_f78d1f187d6243ba8c3af2f010a2b35b",
              "IPY_MODEL_bbda3f14b2ee4a2496aa09ea5608949c"
            ],
            "layout": "IPY_MODEL_feed2eff05e649859f73e170cc4945ba"
          }
        },
        "18b07484bd6a4837bb73f9823d471997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b5ec5f94544b2ba4804d321975efc4",
            "placeholder": "​",
            "style": "IPY_MODEL_4e0d0ec8a9b243b7adfc8c9c83925c47",
            "value": "modules.json: 100%"
          }
        },
        "f78d1f187d6243ba8c3af2f010a2b35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e4d4acc7ee4ddaaafeae9bf4d9669c",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d6b6672c43948f1a82a6222df56053c",
            "value": 349
          }
        },
        "bbda3f14b2ee4a2496aa09ea5608949c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c183dcba06b2407cb5a6d3808f8dce53",
            "placeholder": "​",
            "style": "IPY_MODEL_32ed826181fc44dc86cbf2c192e9fb49",
            "value": " 349/349 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "feed2eff05e649859f73e170cc4945ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b5ec5f94544b2ba4804d321975efc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e0d0ec8a9b243b7adfc8c9c83925c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42e4d4acc7ee4ddaaafeae9bf4d9669c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6b6672c43948f1a82a6222df56053c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c183dcba06b2407cb5a6d3808f8dce53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ed826181fc44dc86cbf2c192e9fb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b53f1d5a18f647798c4f8f96a12e0c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2711d72f477f40aba0e33bbd6c3f78d8",
              "IPY_MODEL_7d5f80b5b8a245ce95243efde9d8073a",
              "IPY_MODEL_49bc21636835480e865a4df5afff5d67"
            ],
            "layout": "IPY_MODEL_2c6aabf6737447ea961252b402ea3bc9"
          }
        },
        "2711d72f477f40aba0e33bbd6c3f78d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_078f1245ac934e0e911bfb9ecb658188",
            "placeholder": "​",
            "style": "IPY_MODEL_1112a9790cf442df8f35baff9badc066",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "7d5f80b5b8a245ce95243efde9d8073a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb1f716815b4f97a0b307b951fe935c",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc6a0db7de9c43cd90e9329941bacccd",
            "value": 116
          }
        },
        "49bc21636835480e865a4df5afff5d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baa9089595a349d8840e22eccb996d25",
            "placeholder": "​",
            "style": "IPY_MODEL_5ba0e37ca42e4e47a2bbc018008bb4c9",
            "value": " 116/116 [00:00&lt;00:00, 9.02kB/s]"
          }
        },
        "2c6aabf6737447ea961252b402ea3bc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "078f1245ac934e0e911bfb9ecb658188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1112a9790cf442df8f35baff9badc066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb1f716815b4f97a0b307b951fe935c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc6a0db7de9c43cd90e9329941bacccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baa9089595a349d8840e22eccb996d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba0e37ca42e4e47a2bbc018008bb4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225d2b69a24d4164b1848ad00bd74902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_728a82adf7604a0a914d0ec77be7cab0",
              "IPY_MODEL_2ca08340e9414629812da743e9b08c3e",
              "IPY_MODEL_2c21b3207ae74b899b20eb3886155dd4"
            ],
            "layout": "IPY_MODEL_7932afbc8846464da398a3f7f4b280cf"
          }
        },
        "728a82adf7604a0a914d0ec77be7cab0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9471543eec524686a9148374c1610ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_564178672b7d4171848d0f7a00167318",
            "value": "README.md: "
          }
        },
        "2ca08340e9414629812da743e9b08c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20f4b6a450534a8f8b496a460c136b74",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38cd989f50374f4fbb33828d66d5ce36",
            "value": 1
          }
        },
        "2c21b3207ae74b899b20eb3886155dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c539c64a3f65488d912dd1210bd0e241",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0e29414f3e473cb3c25f7fd1b9cef5",
            "value": " 10.5k/? [00:00&lt;00:00, 596kB/s]"
          }
        },
        "7932afbc8846464da398a3f7f4b280cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9471543eec524686a9148374c1610ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "564178672b7d4171848d0f7a00167318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f4b6a450534a8f8b496a460c136b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "38cd989f50374f4fbb33828d66d5ce36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c539c64a3f65488d912dd1210bd0e241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0e29414f3e473cb3c25f7fd1b9cef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a436bb7052dd4d3d9106839354419f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8075332d17484a88b26d2d47f27ac816",
              "IPY_MODEL_c2bbbb355f2a457c9e959c08e5535ad9",
              "IPY_MODEL_952b66c0b3da43e4bb543b82d1c52750"
            ],
            "layout": "IPY_MODEL_ba2f7cd3edbe4041ba462275dcdad869"
          }
        },
        "8075332d17484a88b26d2d47f27ac816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b479bbd4290d4c12b2ee64807d4fda36",
            "placeholder": "​",
            "style": "IPY_MODEL_30019ad72e4d4bc880a632fcc6eb4ff4",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "c2bbbb355f2a457c9e959c08e5535ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6278b1e78e3c4d08b4398ff62226cd4e",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb75c0c6b999468590aca76c6ec5a2bf",
            "value": 53
          }
        },
        "952b66c0b3da43e4bb543b82d1c52750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a711fe1116443698e0c213139ba54e5",
            "placeholder": "​",
            "style": "IPY_MODEL_3e8b3f14672043e8bccbd6da7ab27cd7",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.76kB/s]"
          }
        },
        "ba2f7cd3edbe4041ba462275dcdad869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b479bbd4290d4c12b2ee64807d4fda36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30019ad72e4d4bc880a632fcc6eb4ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6278b1e78e3c4d08b4398ff62226cd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb75c0c6b999468590aca76c6ec5a2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a711fe1116443698e0c213139ba54e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8b3f14672043e8bccbd6da7ab27cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00aefa4df8e94235934eabd105f129b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3988aa7f508b480892a086fd3cc9f41b",
              "IPY_MODEL_35515cbe2cb4471598460923e7b47f18",
              "IPY_MODEL_3232134ac7d143caa099dbff802da24b"
            ],
            "layout": "IPY_MODEL_b0429002f52e45d79befcc139d935c5d"
          }
        },
        "3988aa7f508b480892a086fd3cc9f41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d48ccdcca14fecaf37ec6d6c50d407",
            "placeholder": "​",
            "style": "IPY_MODEL_90e04b7a3b994d2a8cfa3e6262124f3b",
            "value": "config.json: 100%"
          }
        },
        "35515cbe2cb4471598460923e7b47f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20a8deecfa0c40db945ca0ec888d1bb3",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41b1ec5c06974f8cb6d89621f1e885d4",
            "value": 612
          }
        },
        "3232134ac7d143caa099dbff802da24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba2f8d466f6146a69ea0f110495b3d82",
            "placeholder": "​",
            "style": "IPY_MODEL_72cf121c1fa44b52bca335341f3ddcc2",
            "value": " 612/612 [00:00&lt;00:00, 58.8kB/s]"
          }
        },
        "b0429002f52e45d79befcc139d935c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98d48ccdcca14fecaf37ec6d6c50d407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e04b7a3b994d2a8cfa3e6262124f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20a8deecfa0c40db945ca0ec888d1bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41b1ec5c06974f8cb6d89621f1e885d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba2f8d466f6146a69ea0f110495b3d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cf121c1fa44b52bca335341f3ddcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31ef5990837b45cba81ceed4c58cd7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_efc458b3327d43af81aaa67bac1dc430",
              "IPY_MODEL_3c9ee1393e344bd49a6d71d165962e76",
              "IPY_MODEL_3c92e740b455443894c67defbda06e2d"
            ],
            "layout": "IPY_MODEL_4f7081bfe840439f8445cdcc58c1594a"
          }
        },
        "efc458b3327d43af81aaa67bac1dc430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b5c1848afe4829baf96aa89327ceb3",
            "placeholder": "​",
            "style": "IPY_MODEL_900ec26799cb4c3ca5f2e0761f5eee3b",
            "value": "model.safetensors: 100%"
          }
        },
        "3c9ee1393e344bd49a6d71d165962e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aadf051c3f724a56a128990e001c6eaa",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14c23066b3934e6cad4a5c965eb0f56d",
            "value": 90868376
          }
        },
        "3c92e740b455443894c67defbda06e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05c58dbc1e5343df8322a8cba82c31e1",
            "placeholder": "​",
            "style": "IPY_MODEL_01ea4e71cbd94ad480da0255f5e9a6c2",
            "value": " 90.9M/90.9M [00:01&lt;00:00, 91.8MB/s]"
          }
        },
        "4f7081bfe840439f8445cdcc58c1594a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9b5c1848afe4829baf96aa89327ceb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "900ec26799cb4c3ca5f2e0761f5eee3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aadf051c3f724a56a128990e001c6eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14c23066b3934e6cad4a5c965eb0f56d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05c58dbc1e5343df8322a8cba82c31e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ea4e71cbd94ad480da0255f5e9a6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "856c484c9beb414c980e05f2450c3c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d5f3636368d4a9f8b4962587cae0d69",
              "IPY_MODEL_1f6fd0be3fe747cfbb90c31556e22b59",
              "IPY_MODEL_7dbfc47c10cf4045b1deb1d12253369d"
            ],
            "layout": "IPY_MODEL_e304d643c01e410c811cae432ee4989d"
          }
        },
        "5d5f3636368d4a9f8b4962587cae0d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd78d5a3a817445e94c031cd67595894",
            "placeholder": "​",
            "style": "IPY_MODEL_07f137b481514257875a3398d1a93cbd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1f6fd0be3fe747cfbb90c31556e22b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3d4d02ac2a449d869d299f40504c0d",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fe8a6c8eee547ea86e23366910654ca",
            "value": 350
          }
        },
        "7dbfc47c10cf4045b1deb1d12253369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b762ea5171f844dda33c4d6c98e9d47e",
            "placeholder": "​",
            "style": "IPY_MODEL_e51cda449ed24e3abb742128eb9dd4a2",
            "value": " 350/350 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "e304d643c01e410c811cae432ee4989d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd78d5a3a817445e94c031cd67595894": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f137b481514257875a3398d1a93cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c3d4d02ac2a449d869d299f40504c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fe8a6c8eee547ea86e23366910654ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b762ea5171f844dda33c4d6c98e9d47e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51cda449ed24e3abb742128eb9dd4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a59e2b1f536c49d0a4b650f9c9503831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_45a36f25bce54362badf2ca6b78b0b12",
              "IPY_MODEL_b8786fb40b6d4ece8bc482843d2c44ff",
              "IPY_MODEL_d8836803a19441b6b95ccb5afc008d3c"
            ],
            "layout": "IPY_MODEL_37f5534eaf0b4cc3a8164ea9d8b65efc"
          }
        },
        "45a36f25bce54362badf2ca6b78b0b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6968bf17e6844cabc0f3b4f13b4960e",
            "placeholder": "​",
            "style": "IPY_MODEL_24902d41a3644868ae46e932aede30ac",
            "value": "vocab.txt: "
          }
        },
        "b8786fb40b6d4ece8bc482843d2c44ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d093b1098ae4fb8b0f08a933882cb27",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94fef472204246a48cd0e54019c0beb4",
            "value": 1
          }
        },
        "d8836803a19441b6b95ccb5afc008d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96244721a68847008b700058b0f4cac2",
            "placeholder": "​",
            "style": "IPY_MODEL_4fe823a757f14e148b7ba82bc2599e08",
            "value": " 232k/? [00:00&lt;00:00, 6.20MB/s]"
          }
        },
        "37f5534eaf0b4cc3a8164ea9d8b65efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6968bf17e6844cabc0f3b4f13b4960e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24902d41a3644868ae46e932aede30ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d093b1098ae4fb8b0f08a933882cb27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "94fef472204246a48cd0e54019c0beb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96244721a68847008b700058b0f4cac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe823a757f14e148b7ba82bc2599e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d83358ea6d6b49b0b57a19c03ba8a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb8348d0f17841ac91a233cb0e470b97",
              "IPY_MODEL_ec60a5d674dd40afac0bb65269509e37",
              "IPY_MODEL_56aee7c9c4e04dc986c4e6b3b2fb7402"
            ],
            "layout": "IPY_MODEL_9b0233b5797e40ff83d4bb530d000065"
          }
        },
        "bb8348d0f17841ac91a233cb0e470b97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3164300829a45e2b15e1c9f1b5937ce",
            "placeholder": "​",
            "style": "IPY_MODEL_8831160df61f4e579416e62d74cd0896",
            "value": "tokenizer.json: "
          }
        },
        "ec60a5d674dd40afac0bb65269509e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6a836ba98704260aea2c8fb77031881",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e05dd3c383b64b06928ddb22f018968e",
            "value": 1
          }
        },
        "56aee7c9c4e04dc986c4e6b3b2fb7402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96b7ce4ba36e4871a14b0d405372d73b",
            "placeholder": "​",
            "style": "IPY_MODEL_51a292cfbe774dffb64476838377fedf",
            "value": " 466k/? [00:00&lt;00:00, 12.3MB/s]"
          }
        },
        "9b0233b5797e40ff83d4bb530d000065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3164300829a45e2b15e1c9f1b5937ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8831160df61f4e579416e62d74cd0896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6a836ba98704260aea2c8fb77031881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e05dd3c383b64b06928ddb22f018968e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96b7ce4ba36e4871a14b0d405372d73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51a292cfbe774dffb64476838377fedf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3c6ca692f614c39993136dc1680a0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4e944a1fb44481fa80bfed5b394529e",
              "IPY_MODEL_89592b477a0043888e2f4cb6eec63c0d",
              "IPY_MODEL_7c61e11457934ad2876701eb874ebbb8"
            ],
            "layout": "IPY_MODEL_ffc97d81e3694a6bb9cd0078c401c4e2"
          }
        },
        "d4e944a1fb44481fa80bfed5b394529e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46362776690a40278dde6682736c6119",
            "placeholder": "​",
            "style": "IPY_MODEL_01f5035370984c48bfbc7054a2a5fd3c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "89592b477a0043888e2f4cb6eec63c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_777de207b4434ababde7359789665710",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d627edfff2d4200911c8b6ed9f2c6cb",
            "value": 112
          }
        },
        "7c61e11457934ad2876701eb874ebbb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6d4acba5f14282878efaf66b84d8fb",
            "placeholder": "​",
            "style": "IPY_MODEL_fab17e5a5c6e4529b8b166afd2fa5b96",
            "value": " 112/112 [00:00&lt;00:00, 7.77kB/s]"
          }
        },
        "ffc97d81e3694a6bb9cd0078c401c4e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46362776690a40278dde6682736c6119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01f5035370984c48bfbc7054a2a5fd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "777de207b4434ababde7359789665710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d627edfff2d4200911c8b6ed9f2c6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6d4acba5f14282878efaf66b84d8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fab17e5a5c6e4529b8b166afd2fa5b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afe29717295b4d72944bc22753a209e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e264fd9e2834a0881110489b5b2fd4c",
              "IPY_MODEL_41f8a30257a24f5aab6ce842cda0a769",
              "IPY_MODEL_ec2226ebe2de403eb2dded96de52b39b"
            ],
            "layout": "IPY_MODEL_d2350f32e36d44858856088fe48aee7c"
          }
        },
        "3e264fd9e2834a0881110489b5b2fd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_725811f08e014446b21423b63f7364f7",
            "placeholder": "​",
            "style": "IPY_MODEL_d8b9108ef2b046b399fcefab31479adb",
            "value": "config.json: 100%"
          }
        },
        "41f8a30257a24f5aab6ce842cda0a769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855b132c2340490ca396b464db3e2ab4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_055d9fc4ca1849cd82c5c3fb79f5130c",
            "value": 190
          }
        },
        "ec2226ebe2de403eb2dded96de52b39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e5ea28c4d124fbe8f68573c08779892",
            "placeholder": "​",
            "style": "IPY_MODEL_2a1da2e21ef7470ead45ccdbfd253d84",
            "value": " 190/190 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "d2350f32e36d44858856088fe48aee7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725811f08e014446b21423b63f7364f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8b9108ef2b046b399fcefab31479adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "855b132c2340490ca396b464db3e2ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055d9fc4ca1849cd82c5c3fb79f5130c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e5ea28c4d124fbe8f68573c08779892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1da2e21ef7470ead45ccdbfd253d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNqMpWmywaJm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79a1bba0"
      },
      "source": [
        "# Task\n",
        "Build an AI-Powered Resume Scanner using SpaCy, BERT, and Streamlit that extracts skills and experience from resumes and matches them to job descriptions. Create a dataset by scraping LinkedIn profiles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dd2961e"
      },
      "source": [
        "## Data acquisition\n",
        "\n",
        "### Subtask:\n",
        "Scrape LinkedIn profiles to create a dataset of skills and experience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d55553"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary library for scraping LinkedIn profiles.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1b9667d",
        "outputId": "06e99342-680b-49a6-f5ad-1a6bcd70cd47"
      },
      "source": [
        "!pip install linkedin-scraper"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linkedin-scraper\n",
            "  Downloading linkedin_scraper-2.11.5-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting selenium (from linkedin-scraper)\n",
            "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from linkedin-scraper) (2.32.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from linkedin-scraper) (5.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->linkedin-scraper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->linkedin-scraper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->linkedin-scraper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->linkedin-scraper) (2025.7.14)\n",
            "Collecting trio~=0.30.0 (from selenium->linkedin-scraper)\n",
            "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.12.2 (from selenium->linkedin-scraper)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium->linkedin-scraper) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium->linkedin-scraper) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->linkedin-scraper) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->linkedin-scraper) (2.4.0)\n",
            "Collecting outcome (from trio~=0.30.0->selenium->linkedin-scraper)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium->linkedin-scraper) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium->linkedin-scraper)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium->linkedin-scraper) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium->linkedin-scraper) (0.16.0)\n",
            "Downloading linkedin_scraper-2.11.5-py3-none-any.whl (29 kB)\n",
            "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.2/499.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium, linkedin-scraper\n",
            "Successfully installed linkedin-scraper-2.11.5 outcome-1.3.0.post0 selenium-4.34.2 trio-0.30.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "255db88f"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries and define a function to scrape LinkedIn profiles using the installed library, focusing on extracting skills and experience. This step addresses instruction 3 and part of instruction 4. Note that directly scraping LinkedIn profiles programmatically without their API or explicit permission violates their terms of service and is ethically questionable. This code is for illustrative purposes and might not work due to LinkedIn's scraping defenses. A more robust and ethical approach would involve using the official LinkedIn API (if available for public profiles) or manually collecting data with user consent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec30cd0c",
        "outputId": "11151abb-b4d1-473f-cba3-0ae801b5a8a6"
      },
      "source": [
        "import pandas as pd\n",
        "from linkedin_scraper import Person\n",
        "\n",
        "def scrape_linkedin_profile(linkedin_url):\n",
        "    \"\"\"Scrapes a LinkedIn profile for skills and experience.\n",
        "\n",
        "    Args:\n",
        "        linkedin_url: The URL of the LinkedIn profile.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the scraped skills and experience, or None if\n",
        "        scraping fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        person = Person(linkedin_url)\n",
        "        skills = [skill.name for skill in person.skills]\n",
        "        experience = []\n",
        "        for job in person.experiences:\n",
        "            experience.append({\n",
        "                'title': job.job_title,\n",
        "                'company': job.company,\n",
        "                'dates': job.date_range,\n",
        "                'description': job.description\n",
        "            })\n",
        "        return {'skills': skills, 'experience': experience}\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {linkedin_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Define target profiles (replace with actual URLs - use with caution and ethically)\n",
        "# NOTE: This is a placeholder and will likely fail due to LinkedIn's scraping defenses.\n",
        "# Real-world scraping requires more sophisticated techniques, ethical considerations,\n",
        "# and adherence to terms of service.\n",
        "target_profiles = [\n",
        "    \"https://www.linkedin.com/in/some-profile-1\",\n",
        "    \"https://www.linkedin.com/in/some-profile-2\",\n",
        "    # Add more profile URLs\n",
        "]\n",
        "\n",
        "scraped_data = []\n",
        "for url in target_profiles:\n",
        "    data = scrape_linkedin_profile(url)\n",
        "    if data:\n",
        "        scraped_data.append({'url': url, **data})\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "if scraped_data:\n",
        "    df_scraped = pd.DataFrame(scraped_data)\n",
        "    display(df_scraped.head())\n",
        "else:\n",
        "    print(\"No data scraped.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error scraping https://www.linkedin.com/in/some-profile-1: Message: session not created: probably user data directory is already in use, please specify a unique value for --user-data-dir argument, or don't use --user-data-dir; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\n",
            "Stacktrace:\n",
            "#0 0x58cabd4162ca <unknown>\n",
            "#1 0x58cabcebd550 <unknown>\n",
            "#2 0x58cabcef79cb <unknown>\n",
            "#3 0x58cabcef2d17 <unknown>\n",
            "#4 0x58cabcf4319e <unknown>\n",
            "#5 0x58cabcf42766 <unknown>\n",
            "#6 0x58cabcf34993 <unknown>\n",
            "#7 0x58cabcf00d6b <unknown>\n",
            "#8 0x58cabcf02141 <unknown>\n",
            "#9 0x58cabd3db2ab <unknown>\n",
            "#10 0x58cabd3df0b9 <unknown>\n",
            "#11 0x58cabd3c2139 <unknown>\n",
            "#12 0x58cabd3dfc68 <unknown>\n",
            "#13 0x58cabd3a660f <unknown>\n",
            "#14 0x58cabd4041f8 <unknown>\n",
            "#15 0x58cabd4043d6 <unknown>\n",
            "#16 0x58cabd4155e6 <unknown>\n",
            "#17 0x7923769abac3 <unknown>\n",
            "\n",
            "Error scraping https://www.linkedin.com/in/some-profile-2: Message: session not created: probably user data directory is already in use, please specify a unique value for --user-data-dir argument, or don't use --user-data-dir; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#sessionnotcreatedexception\n",
            "Stacktrace:\n",
            "#0 0x5993b7e772ca <unknown>\n",
            "#1 0x5993b791e550 <unknown>\n",
            "#2 0x5993b79589cb <unknown>\n",
            "#3 0x5993b7953d17 <unknown>\n",
            "#4 0x5993b79a419e <unknown>\n",
            "#5 0x5993b79a3766 <unknown>\n",
            "#6 0x5993b7995993 <unknown>\n",
            "#7 0x5993b7961d6b <unknown>\n",
            "#8 0x5993b7963141 <unknown>\n",
            "#9 0x5993b7e3c2ab <unknown>\n",
            "#10 0x5993b7e400b9 <unknown>\n",
            "#11 0x5993b7e23139 <unknown>\n",
            "#12 0x5993b7e40c68 <unknown>\n",
            "#13 0x5993b7e0760f <unknown>\n",
            "#14 0x5993b7e651f8 <unknown>\n",
            "#15 0x5993b7e653d6 <unknown>\n",
            "#16 0x5993b7e765e6 <unknown>\n",
            "#17 0x7a83bd48aac3 <unknown>\n",
            "\n",
            "No data scraped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afa5bdc3"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Clean and preprocess the scraped data to prepare it for model training. This may involve tokenization, removing stop words, and handling missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db7805b0"
      },
      "source": [
        "**Reasoning**:\n",
        "Since scraping failed, I need to generate a synthetic dataset to proceed with the data cleaning and preprocessing steps as outlined in the instructions. This dataset should mimic the structure of scraped LinkedIn data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "3f8e154d",
        "outputId": "7c731db3-0aa8-49ff-8cc5-369a9103933d"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "# Step 1: Generate synthetic data\n",
        "data = {\n",
        "    'skills': [\n",
        "        ['Python', 'Data Analysis', 'Machine Learning', 'SQL', 'Cloud Computing'],\n",
        "        ['Java', 'Spring Boot', 'Microservices', 'Docker', 'Kubernetes'],\n",
        "        ['JavaScript', 'React', 'Node.js', 'AWS', 'Agile Methodologies'],\n",
        "        ['C++', 'Embedded Systems', 'RTOS', 'Hardware Design'],\n",
        "        ['Project Management', 'Stakeholder Management', 'Risk Assessment', 'Budgeting']\n",
        "    ],\n",
        "    'experience': [\n",
        "        [\n",
        "            {'title': 'Data Scientist', 'company': 'Tech Innovations Inc.', 'dates': 'Jan 2022 - Present', 'description': 'Developed and deployed machine learning models to improve customer segmentation.'},\n",
        "            {'title': 'Data Analyst', 'company': 'Analytics Solutions Ltd.', 'dates': 'Jun 2020 - Dec 2021', 'description': 'Analyzed large datasets to provide insights and support decision-making.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Software Engineer', 'company': 'Global Systems Co.', 'dates': 'Aug 2019 - Present', 'description': 'Designed and implemented microservices using Java and Spring Boot.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Frontend Developer', 'company': 'Web Solutions Group', 'dates': 'Mar 2021 - Present', 'description': 'Built responsive user interfaces using React and Redux.'},\n",
        "            {'title': 'Intern', 'company': 'Startup Hub', 'dates': 'Jun 2020 - Aug 2020', 'description': 'Assisted senior developers with testing and documentation.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Embedded Software Engineer', 'company': 'Hardware Tech', 'dates': 'Sep 2018 - Present', 'description': 'Developed firmware for new embedded devices.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Project Manager', 'company': 'Consulting Partners', 'dates': 'Apr 2017 - Present', 'description': 'Managed multiple IT projects from initiation to closure.'}\n",
        "        ]\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Handle missing values (not necessary for this synthetic data as none are introduced)\n",
        "# If there were missing values, you would handle them here, e.g.:\n",
        "# df['skills'] = df['skills'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "# df['experience'] = df['experience'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "\n",
        "# Step 3: Combine skills and experience text\n",
        "def combine_text(row):\n",
        "    skills_text = \" \".join(row['skills'] if isinstance(row['skills'], list) else [])\n",
        "    experience_text = \"\"\n",
        "    if isinstance(row['experience'], list):\n",
        "        for job in row['experience']:\n",
        "            if isinstance(job, dict):\n",
        "                experience_text += f\"{job.get('title', '')} {job.get('company', '')} {job.get('description', '')} \"\n",
        "    return skills_text + \" \" + experience_text.strip()\n",
        "\n",
        "df['combined_text'] = df.apply(combine_text, axis=1)\n",
        "\n",
        "# Step 4: Basic text preprocessing (lowercase and remove punctuation)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['combined_text'].apply(preprocess_text)\n",
        "\n",
        "# Step 5: Tokenize the preprocessed text\n",
        "df['tokens'] = df['cleaned_text'].apply(lambda x: x.split())\n",
        "\n",
        "# Step 6: Remove common English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['processed_tokens'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# Step 7: Rejoin the processed tokens into a clean string\n",
        "df['final_processed_text'] = df['processed_tokens'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Step 8: Store in a new column (already done in Step 7, just naming it clearly)\n",
        "df['processed_profile_text'] = df['final_processed_text']\n",
        "\n",
        "# Display the relevant columns to show the result\n",
        "display(df[['skills', 'experience', 'processed_profile_text']].head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'nltk.downloader' has no attribute 'DownloadError'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-105909388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDownloadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-105909388.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corpora/stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mexcept\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDownloadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'nltk.downloader' has no attribute 'DownloadError'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14b78b89"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code failed because the NLTK 'stopwords' resource was not found and the exception handling for `nltk.downloader.DownloadError` was incorrect. I need to fix the NLTK download part to ensure the stopwords are available before using them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "_5OMan1Fw678",
        "outputId": "ed74ded1-02b2-4089-bc85-33e366c61d4f"
      },
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    print(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        print(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading NLTK stopwords: {e}\", file=sys.stderr)\n",
        "        # If download fails, we might need to handle this case,\n",
        "        # but for this task, we'll assume it succeeds or raise error.\n",
        "        raise # Re-raise the exception if download fails\n",
        "\n",
        "# Step 1: Generate synthetic data (re-generating as the previous run failed before completing this)\n",
        "data = {\n",
        "    'skills': [\n",
        "        ['Python', 'Data Analysis', 'Machine Learning', 'SQL', 'Cloud Computing'],\n",
        "        ['Java', 'Spring Boot', 'Microservices', 'Docker', 'Kubernetes'],\n",
        "        ['JavaScript', 'React', 'Node.js', 'AWS', 'Agile Methodologies'],\n",
        "        ['C++', 'Embedded Systems', 'RTOS', 'Hardware Design'],\n",
        "        ['Project Management', 'Stakeholder Management', 'Risk Assessment', 'Budgeting']\n",
        "    ],\n",
        "    'experience': [\n",
        "        [\n",
        "            {'title': 'Data Scientist', 'company': 'Tech Innovations Inc.', 'dates': 'Jan 2022 - Present', 'description': 'Developed and deployed machine learning models to improve customer segmentation.'},\n",
        "            {'title': 'Data Analyst', 'company': 'Analytics Solutions Ltd.', 'dates': 'Jun 2020 - Dec 2021', 'description': 'Analyzed large datasets to provide insights and support decision-making.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Software Engineer', 'company': 'Global Systems Co.', 'dates': 'Aug 2019 - Present', 'description': 'Designed and implemented microservices using Java and Spring Boot.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Frontend Developer', 'company': 'Web Solutions Group', 'dates': 'Mar 2021 - Present', 'description': 'Built responsive user interfaces using React and Redux.'},\n",
        "            {'title': 'Intern', 'company': 'Startup Hub', 'dates': 'Jun 2020 - Aug 2020', 'description': 'Assisted senior developers with testing and documentation.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Embedded Software Engineer', 'company': 'Hardware Tech', 'dates': 'Sep 2018 - Present', 'description': 'Developed firmware for new embedded devices.'}\n",
        "        ],\n",
        "        [\n",
        "            {'title': 'Project Manager', 'company': 'Consulting Partners', 'dates': 'Apr 2017 - Present', 'description': 'Managed multiple IT projects from initiation to closure.'}\n",
        "        ]\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Handle missing values (not necessary for this synthetic data as none are introduced)\n",
        "# If there were missing values, you would handle them here, e.g.:\n",
        "# df['skills'] = df['skills'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "# df['experience'] = df['experience'].apply(lambda x: x if isinstance(x, list) else [])\n",
        "\n",
        "# Step 3: Combine skills and experience text\n",
        "def combine_text(row):\n",
        "    skills_text = \" \".join(row['skills'] if isinstance(row['skills'], list) else [])\n",
        "    experience_text = \"\"\n",
        "    if isinstance(row['experience'], list):\n",
        "        for job in row['experience']:\n",
        "            if isinstance(job, dict):\n",
        "                experience_text += f\"{job.get('title', '')} {job.get('company', '')} {job.get('description', '')} \"\n",
        "    return skills_text + \" \" + experience_text.strip()\n",
        "\n",
        "df['combined_text'] = df.apply(combine_text, axis=1)\n",
        "\n",
        "# Step 4: Basic text preprocessing (lowercase and remove punctuation)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['combined_text'].apply(preprocess_text)\n",
        "\n",
        "# Step 5: Tokenize the preprocessed text\n",
        "df['tokens'] = df['cleaned_text'].apply(lambda x: x.split())\n",
        "\n",
        "# Step 6: Remove common English stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['processed_tokens'] = df['tokens'].apply(lambda x: [word for word in x if word and word not in stop_words]) # Added check for empty string\n",
        "\n",
        "# Step 7: Rejoin the processed tokens into a clean string\n",
        "df['final_processed_text'] = df['processed_tokens'].apply(lambda x: \" \".join(x))\n",
        "\n",
        "# Step 8: Store in a new column (already done in Step 7, just naming it clearly)\n",
        "df['processed_profile_text'] = df['final_processed_text']\n",
        "\n",
        "# Display the relevant columns to show the result\n",
        "display(df[['skills', 'experience', 'processed_profile_text']].head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK stopwords not found. Downloading...\n",
            "NLTK stopwords downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              skills  \\\n",
              "0  [Python, Data Analysis, Machine Learning, SQL,...   \n",
              "1  [Java, Spring Boot, Microservices, Docker, Kub...   \n",
              "2  [JavaScript, React, Node.js, AWS, Agile Method...   \n",
              "3     [C++, Embedded Systems, RTOS, Hardware Design]   \n",
              "4  [Project Management, Stakeholder Management, R...   \n",
              "\n",
              "                                          experience  \\\n",
              "0  [{'title': 'Data Scientist', 'company': 'Tech ...   \n",
              "1  [{'title': 'Software Engineer', 'company': 'Gl...   \n",
              "2  [{'title': 'Frontend Developer', 'company': 'W...   \n",
              "3  [{'title': 'Embedded Software Engineer', 'comp...   \n",
              "4  [{'title': 'Project Manager', 'company': 'Cons...   \n",
              "\n",
              "                              processed_profile_text  \n",
              "0  python data analysis machine learning sql clou...  \n",
              "1  java spring boot microservices docker kubernet...  \n",
              "2  javascript react nodejs aws agile methodologie...  \n",
              "3  c embedded systems rtos hardware design embedd...  \n",
              "4  project management stakeholder management risk...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ee53b7a-695d-4ddc-a57d-5997f52a885f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>skills</th>\n",
              "      <th>experience</th>\n",
              "      <th>processed_profile_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Python, Data Analysis, Machine Learning, SQL,...</td>\n",
              "      <td>[{'title': 'Data Scientist', 'company': 'Tech ...</td>\n",
              "      <td>python data analysis machine learning sql clou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Java, Spring Boot, Microservices, Docker, Kub...</td>\n",
              "      <td>[{'title': 'Software Engineer', 'company': 'Gl...</td>\n",
              "      <td>java spring boot microservices docker kubernet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[JavaScript, React, Node.js, AWS, Agile Method...</td>\n",
              "      <td>[{'title': 'Frontend Developer', 'company': 'W...</td>\n",
              "      <td>javascript react nodejs aws agile methodologie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[C++, Embedded Systems, RTOS, Hardware Design]</td>\n",
              "      <td>[{'title': 'Embedded Software Engineer', 'comp...</td>\n",
              "      <td>c embedded systems rtos hardware design embedd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Project Management, Stakeholder Management, R...</td>\n",
              "      <td>[{'title': 'Project Manager', 'company': 'Cons...</td>\n",
              "      <td>project management stakeholder management risk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee53b7a-695d-4ddc-a57d-5997f52a885f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7ee53b7a-695d-4ddc-a57d-5997f52a885f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7ee53b7a-695d-4ddc-a57d-5997f52a885f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-33dc6cbe-97fb-4b60-938d-05f8287587f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33dc6cbe-97fb-4b60-938d-05f8287587f8')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-33dc6cbe-97fb-4b60-938d-05f8287587f8 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['skills', 'experience', 'processed_profile_text']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"skills\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_profile_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"java spring boot microservices docker kubernetes software engineer global systems co designed implemented microservices using java spring boot\",\n          \"project management stakeholder management risk assessment budgeting project manager consulting partners managed multiple projects initiation closure\",\n          \"javascript react nodejs aws agile methodologies frontend developer web solutions group built responsive user interfaces using react redux intern startup hub assisted senior developers testing documentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba9fd242"
      },
      "source": [
        "## Skill and experience extraction model development\n",
        "\n",
        "### Subtask:\n",
        "Develop a model using SpaCy and BERT to extract skills and experience from the processed data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb5b13d0"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the spaCy model and iterate through the processed text to extract entities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "a1776431",
        "outputId": "a4dd8875-5fc1-482e-b1f8-91d2f24f89bf"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load a pre-trained spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "except OSError:\n",
        "    print(\"SpaCy model 'en_core_web_lg' not found. Downloading...\")\n",
        "    spacy.cli.download('en_core_web_lg')\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "# Initialize columns for extracted skills and experience\n",
        "df['extracted_skills'] = [[] for _ in range(len(df))]\n",
        "df['extracted_experience'] = [[] for _ in range(len(df))]\n",
        "\n",
        "# Iterate and perform NER\n",
        "for index, text in enumerate(df['processed_profile_text']):\n",
        "    doc = nlp(text)\n",
        "    # Extract entities that might represent skills or experience components\n",
        "    # This is a basic approach and might need refinement based on domain knowledge\n",
        "    extracted_entities = []\n",
        "    for ent in doc.ents:\n",
        "        # Consider relevant entity types. This list is a starting point.\n",
        "        if ent.label_ in ['ORG', 'GPE', 'PERSON', 'PRODUCT', 'NORP', 'FAC', 'LOC']:\n",
        "             extracted_entities.append(ent.text)\n",
        "\n",
        "    # Simple heuristic: entities are treated as potential skills/experience mentions\n",
        "    # Further logic would be needed to differentiate and categorize\n",
        "    df.at[index, 'extracted_skills'] = extracted_entities # Storing all as potential skills for now\n",
        "    df.at[index, 'extracted_experience'] = [] # No specific extraction for 'experience' entities in this basic step\n",
        "\n",
        "# Display the DataFrame with new columns\n",
        "display(df[['processed_profile_text', 'extracted_skills', 'extracted_experience']].head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpaCy model 'en_core_web_lg' not found. Downloading...\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              processed_profile_text  \\\n",
              "0  python data analysis machine learning sql clou...   \n",
              "1  java spring boot microservices docker kubernet...   \n",
              "2  javascript react nodejs aws agile methodologie...   \n",
              "3  c embedded systems rtos hardware design embedd...   \n",
              "4  project management stakeholder management risk...   \n",
              "\n",
              "                                    extracted_skills extracted_experience  \n",
              "0  [scientist tech innovations inc, analytics sol...                   []  \n",
              "1  [java, boot microservices docker, global syste...                   []  \n",
              "2                     [javascript, nodejs aws agile]                   []  \n",
              "3                                                 []                   []  \n",
              "4                                                 []                   []  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-100fc2a2-fdea-4253-aef9-c7b93e26fc52\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed_profile_text</th>\n",
              "      <th>extracted_skills</th>\n",
              "      <th>extracted_experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>python data analysis machine learning sql clou...</td>\n",
              "      <td>[scientist tech innovations inc, analytics sol...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>java spring boot microservices docker kubernet...</td>\n",
              "      <td>[java, boot microservices docker, global syste...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>javascript react nodejs aws agile methodologie...</td>\n",
              "      <td>[javascript, nodejs aws agile]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c embedded systems rtos hardware design embedd...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>project management stakeholder management risk...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-100fc2a2-fdea-4253-aef9-c7b93e26fc52')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-100fc2a2-fdea-4253-aef9-c7b93e26fc52 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-100fc2a2-fdea-4253-aef9-c7b93e26fc52');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-06d45275-1398-4be5-acad-41dad5942009\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-06d45275-1398-4be5-acad-41dad5942009')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-06d45275-1398-4be5-acad-41dad5942009 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['processed_profile_text', 'extracted_skills', 'extracted_experience']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"processed_profile_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"java spring boot microservices docker kubernetes software engineer global systems co designed implemented microservices using java spring boot\",\n          \"project management stakeholder management risk assessment budgeting project manager consulting partners managed multiple projects initiation closure\",\n          \"javascript react nodejs aws agile methodologies frontend developer web solutions group built responsive user interfaces using react redux intern startup hub assisted senior developers testing documentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_skills\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extracted_experience\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b0d15e8"
      },
      "source": [
        "## Job description matching\n",
        "\n",
        "### Subtask:\n",
        "Develop a mechanism to match the extracted skills and experience from resumes to job descriptions. This could involve calculating similarity scores between resume and job description embeddings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d2bfca7"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a sample job description, load a pre-trained sentence transformer model, generate embeddings for the profile texts and the job description, calculate cosine similarity, store the scores, and display the results as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717,
          "referenced_widgets": [
            "4986e8ef78544750b134788e08d9acec",
            "18b07484bd6a4837bb73f9823d471997",
            "f78d1f187d6243ba8c3af2f010a2b35b",
            "bbda3f14b2ee4a2496aa09ea5608949c",
            "feed2eff05e649859f73e170cc4945ba",
            "77b5ec5f94544b2ba4804d321975efc4",
            "4e0d0ec8a9b243b7adfc8c9c83925c47",
            "42e4d4acc7ee4ddaaafeae9bf4d9669c",
            "2d6b6672c43948f1a82a6222df56053c",
            "c183dcba06b2407cb5a6d3808f8dce53",
            "32ed826181fc44dc86cbf2c192e9fb49",
            "b53f1d5a18f647798c4f8f96a12e0c82",
            "2711d72f477f40aba0e33bbd6c3f78d8",
            "7d5f80b5b8a245ce95243efde9d8073a",
            "49bc21636835480e865a4df5afff5d67",
            "2c6aabf6737447ea961252b402ea3bc9",
            "078f1245ac934e0e911bfb9ecb658188",
            "1112a9790cf442df8f35baff9badc066",
            "acb1f716815b4f97a0b307b951fe935c",
            "fc6a0db7de9c43cd90e9329941bacccd",
            "baa9089595a349d8840e22eccb996d25",
            "5ba0e37ca42e4e47a2bbc018008bb4c9",
            "225d2b69a24d4164b1848ad00bd74902",
            "728a82adf7604a0a914d0ec77be7cab0",
            "2ca08340e9414629812da743e9b08c3e",
            "2c21b3207ae74b899b20eb3886155dd4",
            "7932afbc8846464da398a3f7f4b280cf",
            "9471543eec524686a9148374c1610ee7",
            "564178672b7d4171848d0f7a00167318",
            "20f4b6a450534a8f8b496a460c136b74",
            "38cd989f50374f4fbb33828d66d5ce36",
            "c539c64a3f65488d912dd1210bd0e241",
            "aa0e29414f3e473cb3c25f7fd1b9cef5",
            "a436bb7052dd4d3d9106839354419f19",
            "8075332d17484a88b26d2d47f27ac816",
            "c2bbbb355f2a457c9e959c08e5535ad9",
            "952b66c0b3da43e4bb543b82d1c52750",
            "ba2f7cd3edbe4041ba462275dcdad869",
            "b479bbd4290d4c12b2ee64807d4fda36",
            "30019ad72e4d4bc880a632fcc6eb4ff4",
            "6278b1e78e3c4d08b4398ff62226cd4e",
            "eb75c0c6b999468590aca76c6ec5a2bf",
            "7a711fe1116443698e0c213139ba54e5",
            "3e8b3f14672043e8bccbd6da7ab27cd7",
            "00aefa4df8e94235934eabd105f129b6",
            "3988aa7f508b480892a086fd3cc9f41b",
            "35515cbe2cb4471598460923e7b47f18",
            "3232134ac7d143caa099dbff802da24b",
            "b0429002f52e45d79befcc139d935c5d",
            "98d48ccdcca14fecaf37ec6d6c50d407",
            "90e04b7a3b994d2a8cfa3e6262124f3b",
            "20a8deecfa0c40db945ca0ec888d1bb3",
            "41b1ec5c06974f8cb6d89621f1e885d4",
            "ba2f8d466f6146a69ea0f110495b3d82",
            "72cf121c1fa44b52bca335341f3ddcc2",
            "31ef5990837b45cba81ceed4c58cd7cc",
            "efc458b3327d43af81aaa67bac1dc430",
            "3c9ee1393e344bd49a6d71d165962e76",
            "3c92e740b455443894c67defbda06e2d",
            "4f7081bfe840439f8445cdcc58c1594a",
            "d9b5c1848afe4829baf96aa89327ceb3",
            "900ec26799cb4c3ca5f2e0761f5eee3b",
            "aadf051c3f724a56a128990e001c6eaa",
            "14c23066b3934e6cad4a5c965eb0f56d",
            "05c58dbc1e5343df8322a8cba82c31e1",
            "01ea4e71cbd94ad480da0255f5e9a6c2",
            "856c484c9beb414c980e05f2450c3c99",
            "5d5f3636368d4a9f8b4962587cae0d69",
            "1f6fd0be3fe747cfbb90c31556e22b59",
            "7dbfc47c10cf4045b1deb1d12253369d",
            "e304d643c01e410c811cae432ee4989d",
            "dd78d5a3a817445e94c031cd67595894",
            "07f137b481514257875a3398d1a93cbd",
            "4c3d4d02ac2a449d869d299f40504c0d",
            "3fe8a6c8eee547ea86e23366910654ca",
            "b762ea5171f844dda33c4d6c98e9d47e",
            "e51cda449ed24e3abb742128eb9dd4a2",
            "a59e2b1f536c49d0a4b650f9c9503831",
            "45a36f25bce54362badf2ca6b78b0b12",
            "b8786fb40b6d4ece8bc482843d2c44ff",
            "d8836803a19441b6b95ccb5afc008d3c",
            "37f5534eaf0b4cc3a8164ea9d8b65efc",
            "b6968bf17e6844cabc0f3b4f13b4960e",
            "24902d41a3644868ae46e932aede30ac",
            "9d093b1098ae4fb8b0f08a933882cb27",
            "94fef472204246a48cd0e54019c0beb4",
            "96244721a68847008b700058b0f4cac2",
            "4fe823a757f14e148b7ba82bc2599e08",
            "d83358ea6d6b49b0b57a19c03ba8a335",
            "bb8348d0f17841ac91a233cb0e470b97",
            "ec60a5d674dd40afac0bb65269509e37",
            "56aee7c9c4e04dc986c4e6b3b2fb7402",
            "9b0233b5797e40ff83d4bb530d000065",
            "f3164300829a45e2b15e1c9f1b5937ce",
            "8831160df61f4e579416e62d74cd0896",
            "f6a836ba98704260aea2c8fb77031881",
            "e05dd3c383b64b06928ddb22f018968e",
            "96b7ce4ba36e4871a14b0d405372d73b",
            "51a292cfbe774dffb64476838377fedf",
            "b3c6ca692f614c39993136dc1680a0ea",
            "d4e944a1fb44481fa80bfed5b394529e",
            "89592b477a0043888e2f4cb6eec63c0d",
            "7c61e11457934ad2876701eb874ebbb8",
            "ffc97d81e3694a6bb9cd0078c401c4e2",
            "46362776690a40278dde6682736c6119",
            "01f5035370984c48bfbc7054a2a5fd3c",
            "777de207b4434ababde7359789665710",
            "4d627edfff2d4200911c8b6ed9f2c6cb",
            "5e6d4acba5f14282878efaf66b84d8fb",
            "fab17e5a5c6e4529b8b166afd2fa5b96",
            "afe29717295b4d72944bc22753a209e3",
            "3e264fd9e2834a0881110489b5b2fd4c",
            "41f8a30257a24f5aab6ce842cda0a769",
            "ec2226ebe2de403eb2dded96de52b39b",
            "d2350f32e36d44858856088fe48aee7c",
            "725811f08e014446b21423b63f7364f7",
            "d8b9108ef2b046b399fcefab31479adb",
            "855b132c2340490ca396b464db3e2ab4",
            "055d9fc4ca1849cd82c5c3fb79f5130c",
            "1e5ea28c4d124fbe8f68573c08779892",
            "2a1da2e21ef7470ead45ccdbfd253d84"
          ]
        },
        "id": "4874ac4f",
        "outputId": "370439ae-ed8e-4724-9c53-26ee65eaa7de"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Step 1: Define a sample job description string\n",
        "job_description = \"We are looking for a Data Scientist with strong skills in Python, machine learning, SQL, and cloud platforms. Experience with model deployment and data analysis is required.\"\n",
        "\n",
        "# Step 2: Load a pre-trained sentence transformer model\n",
        "# Using a smaller model for faster processing\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Step 3: Generate embeddings for processed_profile_text and job description\n",
        "profile_embeddings = model.encode(df['processed_profile_text'].tolist())\n",
        "job_description_embedding = model.encode(job_description)\n",
        "\n",
        "# Step 4: Calculate the cosine similarity between each resume embedding and the job description embedding\n",
        "# Reshape job_description_embedding to be a 2D array for cosine_similarity\n",
        "job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "# Calculate similarity for each profile embedding against the single job description embedding\n",
        "similarity_scores = cosine_similarity(profile_embeddings, job_description_embedding_reshaped)\n",
        "\n",
        "# The result of cosine_similarity is a 2D array, we need the first column\n",
        "similarity_scores = similarity_scores[:, 0]\n",
        "\n",
        "# Step 5: Store the similarity scores in a new column\n",
        "df['job_match_score'] = similarity_scores\n",
        "\n",
        "# Step 6: Display the DataFrame including the 'job_match_score' column\n",
        "display(df[['processed_profile_text', 'job_match_score']].head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4986e8ef78544750b134788e08d9acec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b53f1d5a18f647798c4f8f96a12e0c82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "225d2b69a24d4164b1848ad00bd74902"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a436bb7052dd4d3d9106839354419f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00aefa4df8e94235934eabd105f129b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31ef5990837b45cba81ceed4c58cd7cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "856c484c9beb414c980e05f2450c3c99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a59e2b1f536c49d0a4b650f9c9503831"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d83358ea6d6b49b0b57a19c03ba8a335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3c6ca692f614c39993136dc1680a0ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afe29717295b4d72944bc22753a209e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                              processed_profile_text  job_match_score\n",
              "0  python data analysis machine learning sql clou...         0.590795\n",
              "1  java spring boot microservices docker kubernet...         0.014000\n",
              "2  javascript react nodejs aws agile methodologie...         0.156821\n",
              "3  c embedded systems rtos hardware design embedd...         0.088478\n",
              "4  project management stakeholder management risk...         0.033020"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bdf9f550-cf41-4a74-89e0-c89d86c4884b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>processed_profile_text</th>\n",
              "      <th>job_match_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>python data analysis machine learning sql clou...</td>\n",
              "      <td>0.590795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>java spring boot microservices docker kubernet...</td>\n",
              "      <td>0.014000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>javascript react nodejs aws agile methodologie...</td>\n",
              "      <td>0.156821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c embedded systems rtos hardware design embedd...</td>\n",
              "      <td>0.088478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>project management stakeholder management risk...</td>\n",
              "      <td>0.033020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bdf9f550-cf41-4a74-89e0-c89d86c4884b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bdf9f550-cf41-4a74-89e0-c89d86c4884b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bdf9f550-cf41-4a74-89e0-c89d86c4884b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-79010380-7a53-47bc-aa81-9dabbfd01405\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79010380-7a53-47bc-aa81-9dabbfd01405')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-79010380-7a53-47bc-aa81-9dabbfd01405 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df[['processed_profile_text', 'job_match_score']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"processed_profile_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"java spring boot microservices docker kubernetes software engineer global systems co designed implemented microservices using java spring boot\",\n          \"project management stakeholder management risk assessment budgeting project manager consulting partners managed multiple projects initiation closure\",\n          \"javascript react nodejs aws agile methodologies frontend developer web solutions group built responsive user interfaces using react redux intern startup hub assisted senior developers testing documentation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job_match_score\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.013999915681779385,\n          0.03301981836557388,\n          0.15682056546211243\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb33f23b"
      },
      "source": [
        "## Streamlit application development\n",
        "\n",
        "### Subtask:\n",
        "Build a user interface using Streamlit to allow users to upload resumes, input job descriptions, and view the matching results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46b1af56"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries and load the spaCy and sentence transformer models, including download logic if needed. Set up the basic Streamlit application structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "b9d89512",
        "outputId": "670cafcf-69b2-4269-e737-29dc1b98f26a"
      },
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    print(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        print(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading NLTK stopwords: {e}\", file=sys.stderr)\n",
        "        st.error(\"Failed to download NLTK stopwords. Please check your internet connection.\")\n",
        "        st.stop() # Stop the app if download fails\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "except OSError:\n",
        "    st.write(\"SpaCy model 'en_core_web_lg' not found. Downloading...\")\n",
        "    try:\n",
        "        spacy.cli.download('en_core_web_lg')\n",
        "        nlp = spacy.load('en_core_web_lg')\n",
        "        st.write(\"SpaCy model downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to download SpaCy model: {e}\")\n",
        "        st.stop() # Stop the app if download fails\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop() # Stop the app if load fails\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (basic version based on previous step)\n",
        "def extract_skills_experience(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_entities = []\n",
        "    # Using the same entity types as in the previous extraction step\n",
        "    for ent in doc.ents:\n",
        "         if ent.label_ in ['ORG', 'GPE', 'PERSON', 'PRODUCT', 'NORP', 'FAC', 'LOC']:\n",
        "             extracted_entities.append(ent.text)\n",
        "    return extracted_entities # Returning as a combined list for simplicity in the UI\n",
        "\n",
        "# Define job matching function\n",
        "def get_match_score(resume_text, job_description_text, model):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0 # Return 0 if either text is empty\n",
        "\n",
        "    resume_embedding = model.encode(resume_text)\n",
        "    job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "    # Reshape for cosine_similarity\n",
        "    resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "    job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "    return similarity_score\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume\n",
        "    extracted_info = extract_skills_experience(processed_resume_text, nlp)\n",
        "\n",
        "    # Calculate job match score\n",
        "    match_score = get_match_score(processed_resume_text, processed_job_description_text, model)\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information\n",
        "    st.write(\"### Extracted Skills/Experience (based on general entities):\")\n",
        "    if extracted_info:\n",
        "        st.write(\", \".join(extracted_info))\n",
        "    else:\n",
        "        st.write(\"No specific skills or experience entities extracted.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2549884568.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41b5d156"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `streamlit` library is not installed. Install `streamlit` using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsXBVB7uxuOm",
        "outputId": "af92aa16-e88b-410c-9832-594d7b88759b"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.47.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.48.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.7.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.47.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.47.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72320d9"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that streamlit is installed, rerun the code to build the Streamlit user interface, load the models, and implement the logic for file upload, text input, processing, extraction, matching, and displaying results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b438ef5",
        "outputId": "26c803bb-e667-446d-f2a1-61aac48df8e0"
      },
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    print(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        print(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading NLTK stopwords: {e}\", file=sys.stderr)\n",
        "        st.error(\"Failed to download NLTK stopwords. Please check your internet connection.\")\n",
        "        st.stop() # Stop the app if download fails\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "except OSError:\n",
        "    st.write(\"SpaCy model 'en_core_web_lg' not found. Downloading...\")\n",
        "    try:\n",
        "        spacy.cli.download('en_core_web_lg')\n",
        "        nlp = spacy.load('en_core_web_lg')\n",
        "        st.write(\"SpaCy model downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to download SpaCy model: {e}\")\n",
        "        st.stop() # Stop the app if download fails\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop() # Stop the app if load fails\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (basic version based on previous step)\n",
        "def extract_skills_experience(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_entities = []\n",
        "    # Using the same entity types as in the previous extraction step\n",
        "    for ent in doc.ents:\n",
        "         if ent.label_ in ['ORG', 'GPE', 'PERSON', 'PRODUCT', 'NORP', 'FAC', 'LOC']:\n",
        "             extracted_entities.append(ent.text)\n",
        "    return extracted_entities # Returning as a combined list for simplicity in the UI\n",
        "\n",
        "# Define job matching function\n",
        "def get_match_score(resume_text, job_description_text, model):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0 # Return 0 if either text is empty\n",
        "\n",
        "    resume_embedding = model.encode(resume_text)\n",
        "    job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "    # Reshape for cosine_similarity\n",
        "    resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "    job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "    similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "    return similarity_score\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume\n",
        "    extracted_info = extract_skills_experience(processed_resume_text, nlp)\n",
        "\n",
        "    # Calculate job match score\n",
        "    match_score = get_match_score(processed_resume_text, processed_job_description_text, model)\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information\n",
        "    st.write(\"### Extracted Skills/Experience (based on general entities):\")\n",
        "    if extracted_info:\n",
        "        st.write(\", \".join(extracted_info))\n",
        "    else:\n",
        "        st.write(\"No specific skills or experience entities extracted.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-04 15:51:02.074 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.263 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-08-04 15:51:02.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.270 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.271 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.272 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.278 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.283 Session state does not function when running a script without `streamlit run`\n",
            "2025-08-04 15:51:02.284 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-04 15:51:02.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e87e8e3"
      },
      "source": [
        "## Model deployment\n",
        "\n",
        "### Subtask:\n",
        "Deploy the trained model and the Streamlit application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e07ec36d"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to prepare the necessary files for deployment and choose a platform. Streamlit Sharing is a suitable and straightforward platform for deploying Streamlit apps. The necessary files include the Streamlit script (`app.py`), a `requirements.txt` file, and potentially a `setup.sh` for downloading models. I will create a dummy `app.py` and `requirements.txt` file as placeholders, as the actual Streamlit code is in the previous execution step and will need to be saved to a file named `app.py` manually for actual deployment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d840407",
        "outputId": "5e2fe5d0-fe2c-4f3c-ed8c-75166492f930"
      },
      "source": [
        "# Create a dummy app.py file content (the actual app code would go here)\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os # Import os for path checks\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop() # Stop the app if download fails\n",
        "\n",
        "# Load spaCy model\n",
        "# Check if model is already installed in the default spacy location\n",
        "# This is a simplification; a robust deployment might require more specific path handling\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # Use subprocess or os.system for cli command in a real script if needed,\n",
        "        # but spacy.cli.download might work directly in some envs.\n",
        "        # For deployment, ensure the model is installed during build process.\n",
        "        # spacy.cli.download(SPACY_MODEL)\n",
        "        # A common approach is to add `en_core_web_lg` to requirements.txt\n",
        "        # and ensure it's linked or copied to the correct spacy data path.\n",
        "        # For this example, we'll assume it's handled by requirements or setup.\n",
        "        # If spacy.load still fails, it means the model isn't in the expected path.\n",
        "        # In a real deployment, you'd ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop() # Stop the app if load fails\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "# SentenceTransformer models are typically downloaded to a cache directory.\n",
        "# Ensure this directory is accessible and persistent in the deployment environment.\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop() # Stop the app if load fails\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (basic version based on previous step)\n",
        "def extract_skills_experience(text, nlp_model):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_entities = []\n",
        "    # Using the same entity types as in the previous extraction step\n",
        "    for ent in doc.ents:\n",
        "         if ent.label_ in ['ORG', 'GPE', 'PERSON', 'PRODUCT', 'NORP', 'FAC', 'LOC']:\n",
        "             extracted_entities.append(ent.text)\n",
        "    return extracted_entities # Returning as a combined list for simplicity in the UI\n",
        "\n",
        "# Define job matching function\n",
        "def get_match_score(resume_text, job_description_text, model):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0 # Return 0 if either text is empty\n",
        "\n",
        "    try:\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        # Reshape for cosine_similarity\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "        return float(similarity_score) # Ensure return type is float\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0 # Return 0 on error\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume\n",
        "    extracted_info = extract_skills_experience(processed_resume_text, nlp)\n",
        "\n",
        "    # Calculate job match score\n",
        "    match_score = get_match_score(processed_resume_text, processed_job_description_text, model)\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information\n",
        "    st.write(\"### Extracted Skills/Experience (based on general entities):\")\n",
        "    if extracted_info:\n",
        "        st.write(\", \".join(extracted_info))\n",
        "    else:\n",
        "        st.write(\"No specific skills or experience entities extracted.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)\n",
        "\n",
        "# Note: For actual deployment to platforms like Streamlit Sharing,\n",
        "# you would need to save these contents into physical files in a Git repository\n",
        "# and connect the repository to the deployment platform.\n",
        "# Also, for spaCy models, adding `en_core_web_lg` to requirements.txt\n",
        "# and ensuring a correct linking/loading strategy in `app.py` is crucial.\n",
        "# Streamlit Sharing typically runs `pip install -r requirements.txt`,\n",
        "# which should handle the spaCy model download if specified correctly."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy app.py and requirements.txt content created.\n",
            "\n",
            "--- app.py content ---\n",
            "\n",
            "import streamlit as st\n",
            "import pandas as pd\n",
            "import spacy\n",
            "from sentence_transformers import SentenceTransformer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "import string\n",
            "import nltk\n",
            "from nltk.corpus import stopwords\n",
            "import sys\n",
            "import os # Import os for path checks\n",
            "\n",
            "# Define model paths\n",
            "SPACY_MODEL = 'en_core_web_lg'\n",
            "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
            "\n",
            "# Download necessary NLTK data if not already downloaded\n",
            "try:\n",
            "    nltk.data.find('corpora/stopwords')\n",
            "except LookupError:\n",
            "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
            "    try:\n",
            "        nltk.download('stopwords')\n",
            "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
            "        st.stop() # Stop the app if download fails\n",
            "\n",
            "# Load spaCy model\n",
            "# Check if model is already installed in the default spacy location\n",
            "# This is a simplification; a robust deployment might require more specific path handling\n",
            "try:\n",
            "    nlp = spacy.load(SPACY_MODEL)\n",
            "except OSError:\n",
            "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
            "    try:\n",
            "        # Use subprocess or os.system for cli command in a real script if needed,\n",
            "        # but spacy.cli.download might work directly in some envs.\n",
            "        # For deployment, ensure the model is installed during build process.\n",
            "        # spacy.cli.download(SPACY_MODEL)\n",
            "        # A common approach is to add `en_core_web_lg` to requirements.txt\n",
            "        # and ensure it's linked or copied to the correct spacy data path.\n",
            "        # For this example, we'll assume it's handled by requirements or setup.\n",
            "        # If spacy.load still fails, it means the model isn't in the expected path.\n",
            "        # In a real deployment, you'd ensure `python -m spacy download en_core_web_lg`\n",
            "        # runs during the build process or use a setup script.\n",
            "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
            "        st.stop()\n",
            "\n",
            "    except Exception as e:\n",
            "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
            "        st.stop() # Stop the app if load fails\n",
            "\n",
            "\n",
            "# Load sentence transformer model\n",
            "# SentenceTransformer models are typically downloaded to a cache directory.\n",
            "# Ensure this directory is accessible and persistent in the deployment environment.\n",
            "try:\n",
            "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
            "except Exception as e:\n",
            "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
            "    st.stop() # Stop the app if load fails\n",
            "\n",
            "\n",
            "# Define text preprocessing function (from previous step)\n",
            "stop_words = set(stopwords.words('english'))\n",
            "def preprocess_text(text):\n",
            "    text = text.lower()\n",
            "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
            "    tokens = text.split()\n",
            "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
            "    return \" \".join(processed_tokens)\n",
            "\n",
            "# Define skill and experience extraction function (basic version based on previous step)\n",
            "def extract_skills_experience(text, nlp_model):\n",
            "    doc = nlp_model(text)\n",
            "    extracted_entities = []\n",
            "    # Using the same entity types as in the previous extraction step\n",
            "    for ent in doc.ents:\n",
            "         if ent.label_ in ['ORG', 'GPE', 'PERSON', 'PRODUCT', 'NORP', 'FAC', 'LOC']:\n",
            "             extracted_entities.append(ent.text)\n",
            "    return extracted_entities # Returning as a combined list for simplicity in the UI\n",
            "\n",
            "# Define job matching function\n",
            "def get_match_score(resume_text, job_description_text, model):\n",
            "    if not resume_text or not job_description_text:\n",
            "        return 0.0 # Return 0 if either text is empty\n",
            "\n",
            "    try:\n",
            "        resume_embedding = model.encode(resume_text)\n",
            "        job_description_embedding = model.encode(job_description_text)\n",
            "\n",
            "        # Reshape for cosine_similarity\n",
            "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
            "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
            "\n",
            "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
            "        return float(similarity_score) # Ensure return type is float\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error calculating match score: {e}\")\n",
            "        return 0.0 # Return 0 on error\n",
            "\n",
            "\n",
            "# Streamlit App Title and Description\n",
            "st.title(\"AI-Powered Resume Scanner\")\n",
            "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
            "\n",
            "# File uploader for resume\n",
            "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
            "\n",
            "# Text area for job description\n",
            "job_description_input = st.text_area(\"Enter Job Description\")\n",
            "\n",
            "# Process and display results when file and job description are provided\n",
            "if uploaded_file is not None and job_description_input:\n",
            "    # Read the uploaded file\n",
            "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
            "\n",
            "    st.subheader(\"Processing Resume and Job Description...\")\n",
            "\n",
            "    # Preprocess texts\n",
            "    processed_resume_text = preprocess_text(resume_text)\n",
            "    processed_job_description_text = preprocess_text(job_description_input)\n",
            "\n",
            "    # Extract skills/experience from resume\n",
            "    extracted_info = extract_skills_experience(processed_resume_text, nlp)\n",
            "\n",
            "    # Calculate job match score\n",
            "    match_score = get_match_score(processed_resume_text, processed_job_description_text, model)\n",
            "\n",
            "    st.subheader(\"Results:\")\n",
            "\n",
            "    # Display extracted information\n",
            "    st.write(\"### Extracted Skills/Experience (based on general entities):\")\n",
            "    if extracted_info:\n",
            "        st.write(\", \".join(extracted_info))\n",
            "    else:\n",
            "        st.write(\"No specific skills or experience entities extracted.\")\n",
            "\n",
            "\n",
            "    # Display job match score\n",
            "    st.write(\"### Job Match Score:\")\n",
            "    st.write(f\"{match_score:.2f}\")\n",
            "\n",
            "elif uploaded_file is None and job_description_input:\n",
            "    st.info(\"Please upload a resume file.\")\n",
            "elif uploaded_file is not None and not job_description_input:\n",
            "     st.info(\"Please enter a job description.\")\n",
            "elif uploaded_file is None and not job_description_input:\n",
            "     st.info(\"Please upload a resume file and enter a job description.\")\n",
            "\n",
            "\n",
            "--- requirements.txt content ---\n",
            "\n",
            "streamlit\n",
            "pandas\n",
            "spacy\n",
            "sentence-transformers\n",
            "scikit-learn\n",
            "nltk\n",
            "# Add specific spaCy model as a requirement for easier deployment setup\n",
            "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f9d9dd"
      },
      "source": [
        "## Testing and evaluation\n",
        "\n",
        "### Subtask:\n",
        "Test the application thoroughly and evaluate the performance of the skill/experience extraction and job matching components.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3448354c"
      },
      "source": [
        "**Reasoning**:\n",
        "Manually review the extracted skills and experience and the job match scores from the previously created dataframe to evaluate performance.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e030d62",
        "outputId": "8e8871ef-1581-487a-c62c-59630133af00"
      },
      "source": [
        "# Step 1: Manually review extracted skills and experience\n",
        "print(\"Manually reviewing extracted skills and experience:\")\n",
        "for index, row in df.head().iterrows():\n",
        "    print(f\"\\n--- Resume {index + 1} ---\")\n",
        "    print(f\"Processed Text: {row['processed_profile_text']}\")\n",
        "    print(f\"Extracted Skills/Experience (SpaCy entities): {row['extracted_skills']}\")\n",
        "    print(f\"Original Skills: {row['skills']}\")\n",
        "    print(f\"Original Experience: {row['experience']}\")\n",
        "\n",
        "# Step 2: Manually review job match scores against a sample job description intuition\n",
        "print(\"\\nManually reviewing job match scores:\")\n",
        "sample_job_description = \"We are looking for a Data Scientist with strong skills in Python, machine learning, SQL, and cloud platforms. Experience with model deployment and data analysis is required.\"\n",
        "print(f\"\\nSample Job Description: {sample_job_description}\")\n",
        "for index, row in df.head().iterrows():\n",
        "    print(f\"\\n--- Resume {index + 1} ---\")\n",
        "    print(f\"Processed Text (Snippet): {row['processed_profile_text'][:100]}...\") # Show snippet\n",
        "    print(f\"Job Match Score: {row['job_match_score']:.4f}\")\n",
        "    # Based on the content of the original data and the job description,\n",
        "    # assess if the score seems reasonable.\n",
        "    # Resume 1 is Data Scientist, seems relevant.\n",
        "    # Resume 2 is Software Engineer (Java), seems less relevant.\n",
        "    # Resume 3 is Frontend Developer (JS), seems less relevant.\n",
        "    # Resume 4 is Embedded Software Engineer (C++), seems less relevant.\n",
        "    # Resume 5 is Project Manager, seems less relevant.\n",
        "\n",
        "    # Add a subjective comment based on manual assessment\n",
        "    if index == 0:\n",
        "        print(\"Subjective Assessment: Score seems high and relevant for a Data Scientist role.\")\n",
        "    elif index in [1, 2, 3, 4]:\n",
        "        print(\"Subjective Assessment: Score seems low and less relevant for this Data Scientist role, which is expected.\")\n",
        "\n",
        "# Step 3: Document observations (These are included in the print statements and the subjective assessments above)\n",
        "# Step 4: Consider edge cases (The synthetic data is structured and clean,\n",
        "# real-world resumes/job descriptions with unusual formatting, jargon,\n",
        "# or missing information would require more robust preprocessing and extraction logic).\n",
        "# The current SpaCy entity extraction is basic and relies on general entity types,\n",
        "# which is a significant limitation for specific skills and experience extraction.\n",
        "# The Sentence Transformer model handles general text similarity but might not\n",
        "# capture specific domain-related nuances as effectively as a fine-tuned model."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manually reviewing extracted skills and experience:\n",
            "\n",
            "--- Resume 1 ---\n",
            "Processed Text: python data analysis machine learning sql cloud computing data scientist tech innovations inc developed deployed machine learning models improve customer segmentation data analyst analytics solutions ltd analyzed large datasets provide insights support decisionmaking\n",
            "Extracted Skills/Experience (SpaCy entities): ['scientist tech innovations inc', 'analytics solutions ltd']\n",
            "Original Skills: ['Python', 'Data Analysis', 'Machine Learning', 'SQL', 'Cloud Computing']\n",
            "Original Experience: [{'title': 'Data Scientist', 'company': 'Tech Innovations Inc.', 'dates': 'Jan 2022 - Present', 'description': 'Developed and deployed machine learning models to improve customer segmentation.'}, {'title': 'Data Analyst', 'company': 'Analytics Solutions Ltd.', 'dates': 'Jun 2020 - Dec 2021', 'description': 'Analyzed large datasets to provide insights and support decision-making.'}]\n",
            "\n",
            "--- Resume 2 ---\n",
            "Processed Text: java spring boot microservices docker kubernetes software engineer global systems co designed implemented microservices using java spring boot\n",
            "Extracted Skills/Experience (SpaCy entities): ['java', 'boot microservices docker', 'global systems co']\n",
            "Original Skills: ['Java', 'Spring Boot', 'Microservices', 'Docker', 'Kubernetes']\n",
            "Original Experience: [{'title': 'Software Engineer', 'company': 'Global Systems Co.', 'dates': 'Aug 2019 - Present', 'description': 'Designed and implemented microservices using Java and Spring Boot.'}]\n",
            "\n",
            "--- Resume 3 ---\n",
            "Processed Text: javascript react nodejs aws agile methodologies frontend developer web solutions group built responsive user interfaces using react redux intern startup hub assisted senior developers testing documentation\n",
            "Extracted Skills/Experience (SpaCy entities): ['javascript', 'nodejs aws agile']\n",
            "Original Skills: ['JavaScript', 'React', 'Node.js', 'AWS', 'Agile Methodologies']\n",
            "Original Experience: [{'title': 'Frontend Developer', 'company': 'Web Solutions Group', 'dates': 'Mar 2021 - Present', 'description': 'Built responsive user interfaces using React and Redux.'}, {'title': 'Intern', 'company': 'Startup Hub', 'dates': 'Jun 2020 - Aug 2020', 'description': 'Assisted senior developers with testing and documentation.'}]\n",
            "\n",
            "--- Resume 4 ---\n",
            "Processed Text: c embedded systems rtos hardware design embedded software engineer hardware tech developed firmware new embedded devices\n",
            "Extracted Skills/Experience (SpaCy entities): []\n",
            "Original Skills: ['C++', 'Embedded Systems', 'RTOS', 'Hardware Design']\n",
            "Original Experience: [{'title': 'Embedded Software Engineer', 'company': 'Hardware Tech', 'dates': 'Sep 2018 - Present', 'description': 'Developed firmware for new embedded devices.'}]\n",
            "\n",
            "--- Resume 5 ---\n",
            "Processed Text: project management stakeholder management risk assessment budgeting project manager consulting partners managed multiple projects initiation closure\n",
            "Extracted Skills/Experience (SpaCy entities): []\n",
            "Original Skills: ['Project Management', 'Stakeholder Management', 'Risk Assessment', 'Budgeting']\n",
            "Original Experience: [{'title': 'Project Manager', 'company': 'Consulting Partners', 'dates': 'Apr 2017 - Present', 'description': 'Managed multiple IT projects from initiation to closure.'}]\n",
            "\n",
            "Manually reviewing job match scores:\n",
            "\n",
            "Sample Job Description: We are looking for a Data Scientist with strong skills in Python, machine learning, SQL, and cloud platforms. Experience with model deployment and data analysis is required.\n",
            "\n",
            "--- Resume 1 ---\n",
            "Processed Text (Snippet): python data analysis machine learning sql cloud computing data scientist tech innovations inc develo...\n",
            "Job Match Score: 0.5908\n",
            "Subjective Assessment: Score seems high and relevant for a Data Scientist role.\n",
            "\n",
            "--- Resume 2 ---\n",
            "Processed Text (Snippet): java spring boot microservices docker kubernetes software engineer global systems co designed implem...\n",
            "Job Match Score: 0.0140\n",
            "Subjective Assessment: Score seems low and less relevant for this Data Scientist role, which is expected.\n",
            "\n",
            "--- Resume 3 ---\n",
            "Processed Text (Snippet): javascript react nodejs aws agile methodologies frontend developer web solutions group built respons...\n",
            "Job Match Score: 0.1568\n",
            "Subjective Assessment: Score seems low and less relevant for this Data Scientist role, which is expected.\n",
            "\n",
            "--- Resume 4 ---\n",
            "Processed Text (Snippet): c embedded systems rtos hardware design embedded software engineer hardware tech developed firmware ...\n",
            "Job Match Score: 0.0885\n",
            "Subjective Assessment: Score seems low and less relevant for this Data Scientist role, which is expected.\n",
            "\n",
            "--- Resume 5 ---\n",
            "Processed Text (Snippet): project management stakeholder management risk assessment budgeting project manager consulting partn...\n",
            "Job Match Score: 0.0330\n",
            "Subjective Assessment: Score seems low and less relevant for this Data Scientist role, which is expected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a353b4ba"
      },
      "source": [
        "## Refinement\n",
        "\n",
        "### Subtask:\n",
        "Based on the testing and evaluation, refine the models and the application.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee96cc20"
      },
      "source": [
        "**Reasoning**:\n",
        "Improve the skill and experience extraction logic using SpaCy's Matcher and regular expressions, and update the dummy `app.py` content with the refined logic and refined job matching logic (though the model itself is not fine-tuned), and ensure the UI displays the information clearly. Finally, update the dummy `requirements.txt` and print both files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "fa8ddc59",
        "outputId": "19d2ff40-219b-406c-d37b-ce40db1c2d3a"
      },
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os\n",
        "import re # Import re for regular expressions\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Initialize SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "skill_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"sql\"}],\n",
        "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
        "    [{\"LOWER\": \"java\"}],\n",
        "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
        "    [{\"LOWER\": \"microservices\"}],\n",
        "    [{\"LOWER\": \"docker\"}],\n",
        "    [{\"LOWER\": \"kubernetes\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
        "    [{\"LOWER\": \"aws\"}],\n",
        "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
        "    [{\"LOWER\": \"c++\"}],\n",
        "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
        "    [{\"LOWER\": \"rtos\"}],\n",
        "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
        "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
        "    [{\"LOWER\": \"budgeting\"}]\n",
        "]\n",
        "\n",
        "matcher.add(\"SKILL\", skill_patterns)\n",
        "\n",
        "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
        "# and potentially associated companies. Regex can be complex for this.\n",
        "# A simple regex to find potential job titles followed by company-like words\n",
        "experience_patterns_regex = [\n",
        "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
        "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
        "]\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (Improved version)\n",
        "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_skills = set() # Use a set to avoid duplicates\n",
        "    extracted_experience = set()\n",
        "\n",
        "    # Use SpaCy Matcher for predefined skill patterns\n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        extracted_skills.add(span.text)\n",
        "\n",
        "    # Use Regex for experience patterns\n",
        "    for pattern in experience_patterns_regex:\n",
        "        for match in re.finditer(pattern, text):\n",
        "             extracted_experience.add(match.group(0).strip())\n",
        "\n",
        "\n",
        "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
        "    # Be more selective with NER entities if using pattern matching\n",
        "    # for ent in doc.ents:\n",
        "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
        "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
        "    #          extracted_experience.add(ent.text)\n",
        "    #      # Can add other entity types if they reliably represent skills or roles\n",
        "\n",
        "    return list(extracted_skills), list(extracted_experience)\n",
        "\n",
        "\n",
        "# Define job matching function (refined - ready for weighted similarity if needed)\n",
        "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Base similarity on processed text embedding\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "\n",
        "        # Future refinement: Incorporate extracted skills for a weighted score\n",
        "        # Example (conceptual - requires defined weights and skill matching logic):\n",
        "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
        "        # skill_weight = 0.3 # Example weight\n",
        "        # embedding_weight = 0.7 # Example weight\n",
        "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
        "        # return float(weighted_score)\n",
        "\n",
        "        return float(similarity_score) # Currently returns only embedding similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# Add explanation for extraction and scoring\n",
        "st.info(\"\"\"\n",
        "**How it works:**\n",
        "1.  Upload a text file resume and enter a job description.\n",
        "2.  The application preprocesses the text (lowercase, remove punctuation and common words).\n",
        "3.  It extracts potential skills and experience using pattern matching and general entity recognition.\n",
        "4.  It calculates a match score based on the overall similarity of the processed resume text and job description using a text embedding model.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume using improved logic\n",
        "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "    # Note: For the job description, you might also want to extract skills\n",
        "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "\n",
        "    # Calculate job match score using refined function\n",
        "    # Pass extracted skills if you plan to use them in the matching logic later\n",
        "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
        "\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information clearly\n",
        "    st.write(\"### Extracted Information:\")\n",
        "    st.write(\"**Skills (based on patterns and entities):**\")\n",
        "    if extracted_skills:\n",
        "        st.write(\", \".join(extracted_skills))\n",
        "    else:\n",
        "        st.write(\"No specific skills found based on current patterns.\")\n",
        "\n",
        "    st.write(\"**Experience (based on patterns and entities):**\")\n",
        "    if extracted_experience:\n",
        "        st.write(\", \".join(extracted_experience))\n",
        "    else:\n",
        "        st.write(\"No specific experience details found based on current patterns.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
        "\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Updated dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated triple-quoted string literal (detected at line 261) (ipython-input-4183791060.py, line 248)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4183791060.py\"\u001b[0;36m, line \u001b[0;32m248\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated triple-quoted string literal (detected at line 261)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e1c4028"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to a `SyntaxError: unterminated triple-quoted string literal`. This indicates an issue with how the multiline string for `app_code` was defined or closed. I need to regenerate the full code block for `app_code` and `requirements_content`, ensuring the string is correctly formatted, and then print them again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "aasSx-7SyQMc",
        "outputId": "6181c248-6a2f-4730-804a-dae5252f5df4"
      },
      "source": [
        "# Create a dummy app.py file content (the actual app code would go here)\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os\n",
        "import re # Import re for regular expressions\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Initialize SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "skill_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"sql\"}],\n",
        "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
        "    [{\"LOWER\": \"java\"}],\n",
        "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
        "    [{\"LOWER\": \"microservices\"}],\n",
        "    [{\"LOWER\": \"docker\"}],\n",
        "    [{\"LOWER\": \"kubernetes\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
        "    [{\"LOWER\": \"aws\"}],\n",
        "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
        "    [{\"LOWER\": \"c++\"}],\n",
        "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
        "    [{\"LOWER\": \"rtos\"}],\n",
        "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
        "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
        "    [{\"LOWER\": \"budgeting\"}]\n",
        "]\n",
        "\n",
        "matcher.add(\"SKILL\", skill_patterns)\n",
        "\n",
        "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
        "# and potentially associated companies. Regex can be complex for this.\n",
        "# A simple regex to find potential job titles followed by company-like words\n",
        "experience_patterns_regex = [\n",
        "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
        "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
        "]\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (Improved version)\n",
        "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_skills = set() # Use a set to avoid duplicates\n",
        "    extracted_experience = set()\n",
        "\n",
        "    # Use SpaCy Matcher for predefined skill patterns\n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        extracted_skills.add(span.text)\n",
        "\n",
        "    # Use Regex for experience patterns\n",
        "    for pattern in experience_patterns_regex:\n",
        "        for match in re.finditer(pattern, text):\n",
        "             extracted_experience.add(match.group(0).strip())\n",
        "\n",
        "\n",
        "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
        "    # Be more selective with NER entities if using pattern matching\n",
        "    # for ent in doc.ents:\n",
        "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
        "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
        "    #          extracted_experience.add(ent.text)\n",
        "    #      # Can add other entity types if they reliably represent skills or roles\n",
        "\n",
        "    return list(extracted_skills), list(extracted_experience)\n",
        "\n",
        "\n",
        "# Define job matching function (refined - ready for weighted similarity if needed)\n",
        "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Base similarity on processed text embedding\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "\n",
        "        # Future refinement: Incorporate extracted skills for a weighted score\n",
        "        # Example (conceptual - requires defined weights and skill matching logic):\n",
        "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
        "        # skill_weight = 0.3 # Example weight\n",
        "        # embedding_weight = 0.7 # Example weight\n",
        "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
        "        # return float(weighted_score)\n",
        "\n",
        "        return float(similarity_score) # Currently returns only embedding similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# Add explanation for extraction and scoring\n",
        "st.info(\"\"\"\n",
        "**How it works:**\n",
        "1.  Upload a text file resume and enter a job description.\n",
        "2.  The application preprocesses the text (lowercase, remove punctuation and common words).\n",
        "3.  It extracts potential skills and experience using pattern matching and general entity recognition.\n",
        "4.  It calculates a match score based on the overall similarity of the processed resume text and job description using a text embedding model.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume using improved logic\n",
        "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "    # Note: For the job description, you might also want to extract skills\n",
        "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "\n",
        "    # Calculate job match score using refined function\n",
        "    # Pass extracted skills if you plan to use them in the matching logic later\n",
        "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
        "\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information clearly\n",
        "    st.write(\"### Extracted Information:\")\n",
        "    st.write(\"**Skills (based on patterns and entities):**\")\n",
        "    if extracted_skills:\n",
        "        st.write(\", \".join(extracted_skills))\n",
        "    else:\n",
        "        st.write(\"No specific skills found based on current patterns.\")\n",
        "\n",
        "    st.write(\"**Experience (based on patterns and entities):**\")\n",
        "    if extracted_experience:\n",
        "        st.write(\", \".join(extracted_experience))\n",
        "    else:\n",
        "        st.write(\"No specific experience details found based on current patterns.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
        "\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Updated dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3820057930.py, line 172)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3820057930.py\"\u001b[0;36m, line \u001b[0;32m172\u001b[0m\n\u001b[0;31m    **How it works:**\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dfc146"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed due to a `SyntaxError: invalid syntax` in the `app_code` string, specifically at the line `**How it works:**`. This is because the triple-quoted string is being interpreted as Python code within the notebook environment, and markdown-like syntax is causing the error. To fix this, I need to escape the markdown characters that are causing issues or use a different way to represent the multiline string, like joining lines with newline characters. Regenerating the full code block with corrected string formatting for `app_code` is necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "s8TK2SGwyWUc",
        "outputId": "29adfe1d-4206-413d-9c4c-9b57cb68e48a"
      },
      "source": [
        "# Create a dummy app.py file content (the actual app code would go here)\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os\n",
        "import re # Import re for regular expressions\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Initialize SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "skill_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"sql\"}],\n",
        "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
        "    [{\"LOWER\": \"java\"}],\n",
        "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
        "    [{\"LOWER\": \"microservices\"}],\n",
        "    [{\"LOWER\": \"docker\"}],\n",
        "    [{\"LOWER\": \"kubernetes\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
        "    [{\"LOWER\": \"aws\"}],\n",
        "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
        "    [{\"LOWER\": \"c++\"}],\n",
        "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
        "    [{\"LOWER\": \"rtos\"}],\n",
        "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
        "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
        "    [{\"LOWER\": \"budgeting\"}]\n",
        "]\n",
        "\n",
        "matcher.add(\"SKILL\", skill_patterns)\n",
        "\n",
        "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
        "# and potentially associated companies. Regex can be complex for this.\n",
        "# A simple regex to find potential job titles followed by company-like words\n",
        "experience_patterns_regex = [\n",
        "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
        "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
        "]\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (Improved version)\n",
        "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_skills = set() # Use a set to avoid duplicates\n",
        "    extracted_experience = set()\n",
        "\n",
        "    # Use SpaCy Matcher for predefined skill patterns\n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        extracted_skills.add(span.text)\n",
        "\n",
        "    # Use Regex for experience patterns\n",
        "    for pattern in experience_patterns_regex:\n",
        "        for match in re.finditer(pattern, text):\n",
        "             extracted_experience.add(match.group(0).strip())\n",
        "\n",
        "\n",
        "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
        "    # Be more selective with NER entities if using pattern matching\n",
        "    # for ent in doc.ents:\n",
        "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
        "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
        "    #          extracted_experience.add(ent.text)\n",
        "    #      # Can add other entity types if they reliably represent skills or roles\n",
        "\n",
        "    return list(extracted_skills), list(extracted_experience)\n",
        "\n",
        "\n",
        "# Define job matching function (refined - ready for weighted similarity if needed)\n",
        "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Base similarity on processed text embedding\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "\n",
        "        # Future refinement: Incorporate extracted skills for a weighted score\n",
        "        # Example (conceptual - requires defined weights and skill matching logic):\n",
        "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
        "        # skill_weight = 0.3 # Example weight\n",
        "        # embedding_weight = 0.7 # Example weight\n",
        "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
        "        # return float(weighted_score)\n",
        "\n",
        "        return float(similarity_score) # Currently returns only embedding similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# Add explanation for extraction and scoring using st.markdown\n",
        "st.markdown(\"\"\"\n",
        "**How it works:**\n",
        "1.  Upload a text file resume and enter a job description.\n",
        "2.  The application preprocesses the text (lowercase, remove punctuation and common words).\n",
        "3.  It extracts potential skills and experience using pattern matching and general entity recognition.\n",
        "4.  It calculates a match score based on the overall similarity of the processed resume text and job description using a text embedding model.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume using improved logic\n",
        "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "    # Note: For the job description, you might also want to extract skills\n",
        "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "\n",
        "    # Calculate job match score using refined function\n",
        "    # Pass extracted skills if you plan to use them in the matching logic later\n",
        "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
        "\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information clearly\n",
        "    st.write(\"### Extracted Information:\")\n",
        "    st.write(\"**Skills (based on patterns and entities):**\")\n",
        "    if extracted_skills:\n",
        "        st.write(\", \".join(extracted_skills))\n",
        "    else:\n",
        "        st.write(\"No specific skills found based on current patterns.\")\n",
        "\n",
        "    st.write(\"**Experience (based on patterns and entities):**\")\n",
        "    if extracted_experience:\n",
        "        st.write(\", \".join(extracted_experience))\n",
        "    else:\n",
        "        st.write(\"No specific experience details found based on current patterns.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
        "\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Updated dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2790942038.py, line 172)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2790942038.py\"\u001b[0;36m, line \u001b[0;32m172\u001b[0m\n\u001b[0;31m    **How it works:**\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93961ad3"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block still failed with a `SyntaxError: invalid syntax` at the same line within the triple-quoted string for `app_code`. This indicates that the markdown-like syntax `**How it works:**` is still causing issues within the Python string literal itself, even though it's intended for `st.markdown`. The best approach is to construct the multiline string using explicit newline characters (`\\n`) and potentially f-strings for clarity, avoiding the triple-quoted string format for the `app_code` variable entirely, or at least ensuring no problematic characters exist within it that conflict with Python's string parsing. I will regenerate the code, carefully constructing the `app_code` string.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK88BvyByf32",
        "outputId": "6f0777bc-2470-4c27-8ef9-6d437748ea88"
      },
      "source": [
        "# Create a dummy app.py file content (the actual app code would go here)\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os\n",
        "import re # Import re for regular expressions\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Initialize SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "skill_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"sql\"}],\n",
        "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
        "    [{\"LOWER\": \"java\"}],\n",
        "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
        "    [{\"LOWER\": \"microservices\"}],\n",
        "    [{\"LOWER\": \"docker\"}],\n",
        "    [{\"LOWER\": \"kubernetes\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
        "    [{\"LOWER\": \"aws\"}],\n",
        "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
        "    [{\"LOWER\": \"c++\"}],\n",
        "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
        "    [{\"LOWER\": \"rtos\"}],\n",
        "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
        "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
        "    [{\"LOWER\": \"budgeting\"}]\n",
        "]\n",
        "\n",
        "matcher.add(\"SKILL\", skill_patterns)\n",
        "\n",
        "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
        "# and potentially associated companies. Regex can be complex for this.\n",
        "# A simple regex to find potential job titles followed by company-like words\n",
        "experience_patterns_regex = [\n",
        "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
        "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
        "]\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (Improved version)\n",
        "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_skills = set() # Use a set to avoid duplicates\n",
        "    extracted_experience = set()\n",
        "\n",
        "    # Use SpaCy Matcher for predefined skill patterns\n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        extracted_skills.add(span.text)\n",
        "\n",
        "    # Use Regex for experience patterns\n",
        "    for pattern in experience_patterns_regex:\n",
        "        for match in re.finditer(pattern, text):\n",
        "             extracted_experience.add(match.group(0).strip())\n",
        "\n",
        "\n",
        "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
        "    # Be more selective with NER entities if using pattern matching\n",
        "    # for ent in doc.ents:\n",
        "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
        "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
        "    #          extracted_experience.add(ent.text)\n",
        "    #      # Can add other entity types if they reliably represent skills or roles\n",
        "\n",
        "    return list(extracted_skills), list(extracted_experience)\n",
        "\n",
        "\n",
        "# Define job matching function (refined - ready for weighted similarity if needed)\n",
        "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Base similarity on processed text embedding\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "\n",
        "        # Future refinement: Incorporate extracted skills for a weighted score\n",
        "        # Example (conceptual - requires defined weights and skill matching logic):\n",
        "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
        "        # skill_weight = 0.3 # Example weight\n",
        "        # embedding_weight = 0.7 # Example weight\n",
        "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
        "        # return float(weighted_score)\n",
        "\n",
        "        return float(similarity_score) # Currently returns only embedding similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# Add explanation for extraction and scoring using st.markdown\n",
        "st.markdown(\"**How it works:**\")\n",
        "st.markdown(\"1.  Upload a text file resume and enter a job description.\")\n",
        "st.markdown(\"2.  The application preprocesses the text (lowercase, remove punctuation and common words).\")\n",
        "st.markdown(\"3.  It extracts potential skills and experience using pattern matching and general entity recognition.\")\n",
        "st.markdown(\"4.  It calculates a match score based on the overall text similarity of the processed resume text and job description using a text embedding model.\")\n",
        "\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume using improved logic\n",
        "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "    # Note: For the job description, you might also want to extract skills\n",
        "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "\n",
        "    # Calculate job match score using refined function\n",
        "    # Pass extracted skills if you plan to use them in the matching logic later\n",
        "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
        "\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information clearly\n",
        "    st.write(\"### Extracted Information:\")\n",
        "    st.write(\"**Skills (based on patterns and entities):**\")\n",
        "    if extracted_skills:\n",
        "        st.write(\", \".join(extracted_skills))\n",
        "    else:\n",
        "        st.write(\"No specific skills found based on current patterns.\")\n",
        "\n",
        "    st.write(\"**Experience (based on patterns and entities):**\")\n",
        "    if extracted_experience:\n",
        "        st.write(\", \".join(extracted_experience))\n",
        "    else:\n",
        "        st.write(\"No specific experience details found based on current patterns.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
        "\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Updated dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dummy app.py and requirements.txt content created.\n",
            "\n",
            "--- app.py content ---\n",
            "\n",
            "import streamlit as st\n",
            "import pandas as pd\n",
            "import spacy\n",
            "from spacy.matcher import Matcher\n",
            "from sentence_transformers import SentenceTransformer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "import string\n",
            "import nltk\n",
            "from nltk.corpus import stopwords\n",
            "import sys\n",
            "import os\n",
            "import re # Import re for regular expressions\n",
            "\n",
            "# Define model paths\n",
            "SPACY_MODEL = 'en_core_web_lg'\n",
            "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
            "\n",
            "# Download necessary NLTK data if not already downloaded\n",
            "try:\n",
            "    nltk.data.find('corpora/stopwords')\n",
            "except LookupError:\n",
            "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
            "    try:\n",
            "        nltk.download('stopwords')\n",
            "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
            "        st.stop()\n",
            "\n",
            "# Load spaCy model\n",
            "try:\n",
            "    nlp = spacy.load(SPACY_MODEL)\n",
            "except OSError:\n",
            "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
            "    try:\n",
            "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
            "        # runs during the build process or use a setup script.\n",
            "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
            "        st.stop()\n",
            "    except Exception as e:\n",
            "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
            "        st.stop()\n",
            "\n",
            "# Initialize SpaCy Matcher\n",
            "matcher = Matcher(nlp.vocab)\n",
            "\n",
            "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
            "# This is a basic set, real-world would need many more patterns.\n",
            "skill_patterns = [\n",
            "    [{\"LOWER\": \"python\"}],\n",
            "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
            "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
            "    [{\"LOWER\": \"sql\"}],\n",
            "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
            "    [{\"LOWER\": \"java\"}],\n",
            "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
            "    [{\"LOWER\": \"microservices\"}],\n",
            "    [{\"LOWER\": \"docker\"}],\n",
            "    [{\"LOWER\": \"kubernetes\"}],\n",
            "    [{\"LOWER\": \"javascript\"}],\n",
            "    [{\"LOWER\": \"react\"}],\n",
            "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
            "    [{\"LOWER\": \"aws\"}],\n",
            "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
            "    [{\"LOWER\": \"c++\"}],\n",
            "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
            "    [{\"LOWER\": \"rtos\"}],\n",
            "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
            "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
            "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
            "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
            "    [{\"LOWER\": \"budgeting\"}]\n",
            "]\n",
            "\n",
            "matcher.add(\"SKILL\", skill_patterns)\n",
            "\n",
            "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
            "# This is a basic set, real-world would need many more patterns.\n",
            "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
            "# and potentially associated companies. Regex can be complex for this.\n",
            "# A simple regex to find potential job titles followed by company-like words\n",
            "experience_patterns_regex = [\n",
            "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
            "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
            "]\n",
            "\n",
            "\n",
            "# Load sentence transformer model\n",
            "try:\n",
            "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
            "except Exception as e:\n",
            "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
            "    st.stop()\n",
            "\n",
            "\n",
            "# Define text preprocessing function (from previous step)\n",
            "stop_words = set(stopwords.words('english'))\n",
            "def preprocess_text(text):\n",
            "    text = text.lower()\n",
            "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
            "    tokens = text.split()\n",
            "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
            "    return \" \".join(processed_tokens)\n",
            "\n",
            "# Define skill and experience extraction function (Improved version)\n",
            "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
            "    doc = nlp_model(text)\n",
            "    extracted_skills = set() # Use a set to avoid duplicates\n",
            "    extracted_experience = set()\n",
            "\n",
            "    # Use SpaCy Matcher for predefined skill patterns\n",
            "    matches = matcher(doc)\n",
            "    for match_id, start, end in matches:\n",
            "        span = doc[start:end]\n",
            "        extracted_skills.add(span.text)\n",
            "\n",
            "    # Use Regex for experience patterns\n",
            "    for pattern in experience_patterns_regex:\n",
            "        for match in re.finditer(pattern, text):\n",
            "             extracted_experience.add(match.group(0).strip())\n",
            "\n",
            "\n",
            "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
            "    # Be more selective with NER entities if using pattern matching\n",
            "    # for ent in doc.ents:\n",
            "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
            "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
            "    #          extracted_experience.add(ent.text)\n",
            "    #      # Can add other entity types if they reliably represent skills or roles\n",
            "\n",
            "    return list(extracted_skills), list(extracted_experience)\n",
            "\n",
            "\n",
            "# Define job matching function (refined - ready for weighted similarity if needed)\n",
            "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
            "    if not resume_text or not job_description_text:\n",
            "        return 0.0\n",
            "\n",
            "    try:\n",
            "        # Base similarity on processed text embedding\n",
            "        resume_embedding = model.encode(resume_text)\n",
            "        job_description_embedding = model.encode(job_description_text)\n",
            "\n",
            "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
            "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
            "\n",
            "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
            "\n",
            "        # Future refinement: Incorporate extracted skills for a weighted score\n",
            "        # Example (conceptual - requires defined weights and skill matching logic):\n",
            "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
            "        # skill_weight = 0.3 # Example weight\n",
            "        # embedding_weight = 0.7 # Example weight\n",
            "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
            "        # return float(weighted_score)\n",
            "\n",
            "        return float(similarity_score) # Currently returns only embedding similarity\n",
            "\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error calculating match score: {e}\")\n",
            "        return 0.0\n",
            "\n",
            "\n",
            "# Streamlit App Title and Description\n",
            "st.title(\"AI-Powered Resume Scanner\")\n",
            "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
            "\n",
            "# Add explanation for extraction and scoring using st.markdown\n",
            "st.markdown(\"**How it works:**\")\n",
            "st.markdown(\"1.  Upload a text file resume and enter a job description.\")\n",
            "st.markdown(\"2.  The application preprocesses the text (lowercase, remove punctuation and common words).\")\n",
            "st.markdown(\"3.  It extracts potential skills and experience using pattern matching and general entity recognition.\")\n",
            "st.markdown(\"4.  It calculates a match score based on the overall text similarity of the processed resume text and job description using a text embedding model.\")\n",
            "\n",
            "\n",
            "# File uploader for resume\n",
            "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
            "\n",
            "# Text area for job description\n",
            "job_description_input = st.text_area(\"Enter Job Description\")\n",
            "\n",
            "# Process and display results when file and job description are provided\n",
            "if uploaded_file is not None and job_description_input:\n",
            "    # Read the uploaded file\n",
            "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
            "\n",
            "    st.subheader(\"Processing Resume and Job Description...\")\n",
            "\n",
            "    # Preprocess texts\n",
            "    processed_resume_text = preprocess_text(resume_text)\n",
            "    processed_job_description_text = preprocess_text(job_description_input)\n",
            "\n",
            "    # Extract skills/experience from resume using improved logic\n",
            "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
            "\n",
            "    # Note: For the job description, you might also want to extract skills\n",
            "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
            "\n",
            "\n",
            "    # Calculate job match score using refined function\n",
            "    # Pass extracted skills if you plan to use them in the matching logic later\n",
            "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
            "\n",
            "\n",
            "    st.subheader(\"Results:\")\n",
            "\n",
            "    # Display extracted information clearly\n",
            "    st.write(\"### Extracted Information:\")\n",
            "    st.write(\"**Skills (based on patterns and entities):**\")\n",
            "    if extracted_skills:\n",
            "        st.write(\", \".join(extracted_skills))\n",
            "    else:\n",
            "        st.write(\"No specific skills found based on current patterns.\")\n",
            "\n",
            "    st.write(\"**Experience (based on patterns and entities):**\")\n",
            "    if extracted_experience:\n",
            "        st.write(\", \".join(extracted_experience))\n",
            "    else:\n",
            "        st.write(\"No specific experience details found based on current patterns.\")\n",
            "\n",
            "\n",
            "    # Display job match score\n",
            "    st.write(\"### Job Match Score:\")\n",
            "    st.write(f\"{match_score:.2f}\")\n",
            "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
            "\n",
            "\n",
            "elif uploaded_file is None and job_description_input:\n",
            "    st.info(\"Please upload a resume file.\")\n",
            "elif uploaded_file is not None and not job_description_input:\n",
            "     st.info(\"Please enter a job description.\")\n",
            "elif uploaded_file is None and not job_description_input:\n",
            "     st.info(\"Please upload a resume file and enter a job description.\")\n",
            "\n",
            "\n",
            "--- requirements.txt content ---\n",
            "\n",
            "streamlit\n",
            "pandas\n",
            "spacy\n",
            "sentence-transformers\n",
            "scikit-learn\n",
            "nltk\n",
            "# Add specific spaCy model as a requirement for easier deployment setup\n",
            "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea60dfff"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Scraping LinkedIn profiles directly failed due to LinkedIn's anti-scraping measures, necessitating the use of synthetic data for subsequent steps.\n",
        "*   Preprocessing steps including lowercasing, punctuation removal, tokenization, and stop word removal were successfully applied to the text data.\n",
        "*   Initial skill and experience extraction using SpaCy's general Named Entity Recognition (NER) was not specific enough for identifying technical skills and detailed experience.\n",
        "*   Job matching using Sentence Transformer embeddings and cosine similarity showed intuitively reasonable scores with clean synthetic data, indicating its potential but also highlighting its reliance on accurate input data.\n",
        "*   Refinement involved implementing SpaCy's `Matcher` and regular expressions for potentially better skill and experience extraction, although the pattern sets used were basic examples.\n",
        "*   The final Streamlit application code (`app.py`) includes necessary components for UI, preprocessing, extraction, and matching, with instructions for deployment via `requirements.txt`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Enhance skill and experience extraction by creating a comprehensive and domain-specific set of patterns for SpaCy's `Matcher` and refining regex patterns for experience details. Consider exploring more advanced techniques like training custom NER models or using transformer-based models for token classification specifically for skills and roles.\n",
        "*   Improve the job matching logic by incorporating the extracted skills and experience into a weighted similarity score, giving more importance to matching specific required skills mentioned in the job description.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da6cfe96",
        "outputId": "f6cbd470-72d9-4b9c-aae9-1de358c3b369"
      },
      "source": [
        "# Create a dummy app.py file content (the actual app code would go here)\n",
        "# Using explicit newlines and f-strings for clarity and to avoid syntax issues\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import sys\n",
        "import os\n",
        "import re # Import re for regular expressions\n",
        "\n",
        "# Define model paths\n",
        "SPACY_MODEL = 'en_core_web_lg'\n",
        "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Download necessary NLTK data if not already downloaded\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except LookupError:\n",
        "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
        "    try:\n",
        "        nltk.download('stopwords')\n",
        "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(SPACY_MODEL)\n",
        "except OSError:\n",
        "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
        "    try:\n",
        "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
        "        # runs during the build process or use a setup script.\n",
        "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "# Initialize SpaCy Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "skill_patterns = [\n",
        "    [{\"LOWER\": \"python\"}],\n",
        "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
        "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
        "    [{\"LOWER\": \"sql\"}],\n",
        "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
        "    [{\"LOWER\": \"java\"}],\n",
        "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
        "    [{\"LOWER\": \"microservices\"}],\n",
        "    [{\"LOWER\": \"docker\"}],\n",
        "    [{\"LOWER\": \"kubernetes\"}],\n",
        "    [{\"LOWER\": \"javascript\"}],\n",
        "    [{\"LOWER\": \"react\"}],\n",
        "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
        "    [{\"LOWER\": \"aws\"}],\n",
        "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
        "    [{\"LOWER\": \"c++\"}],\n",
        "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
        "    [{\"LOWER\": \"rtos\"}],\n",
        "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
        "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
        "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
        "    [{\"LOWER\": \"budgeting\"}]\n",
        "]\n",
        "\n",
        "matcher.add(\"SKILL\", skill_patterns)\n",
        "\n",
        "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
        "# This is a basic set, real-world would need many more patterns.\n",
        "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
        "# and potentially associated companies. Regex can be complex for this.\n",
        "# A simple regex to find potential job titles followed by company-like words\n",
        "experience_patterns_regex = [\n",
        "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
        "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
        "]\n",
        "\n",
        "\n",
        "# Load sentence transformer model\n",
        "try:\n",
        "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
        "except Exception as e:\n",
        "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "# Define text preprocessing function (from previous step)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    tokens = text.split()\n",
        "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
        "    return \" \".join(processed_tokens)\n",
        "\n",
        "# Define skill and experience extraction function (Improved version)\n",
        "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
        "    doc = nlp_model(text)\n",
        "    extracted_skills = set() # Use a set to avoid duplicates\n",
        "    extracted_experience = set()\n",
        "\n",
        "    # Use SpaCy Matcher for predefined skill patterns\n",
        "    matches = matcher(doc)\n",
        "    for match_id, start, end in matches:\n",
        "        span = doc[start:end]\n",
        "        extracted_skills.add(span.text)\n",
        "\n",
        "    # Use Regex for experience patterns\n",
        "    for pattern in experience_patterns_regex:\n",
        "        for match in re.finditer(pattern, text):\n",
        "             extracted_experience.add(match.group(0).strip())\n",
        "\n",
        "\n",
        "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
        "    # Be more selective with NER entities if using pattern matching\n",
        "    # for ent in doc.ents:\n",
        "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
        "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
        "    #          extracted_experience.add(ent.text)\n",
        "    #      # Can add other entity types if they reliably represent skills or roles\n",
        "\n",
        "    return list(extracted_skills), list(extracted_experience)\n",
        "\n",
        "\n",
        "# Define job matching function (refined - ready for weighted similarity if needed)\n",
        "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
        "    if not resume_text or not job_description_text:\n",
        "        return 0.0\n",
        "\n",
        "    try:\n",
        "        # Base similarity on processed text embedding\n",
        "        resume_embedding = model.encode(resume_text)\n",
        "        job_description_embedding = model.encode(job_description_text)\n",
        "\n",
        "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
        "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
        "\n",
        "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
        "\n",
        "        # Future refinement: Incorporate extracted skills for a weighted score\n",
        "        # Example (conceptual - requires defined weights and skill matching logic):\n",
        "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
        "        # skill_weight = 0.3 # Example weight\n",
        "        # embedding_weight = 0.7 # Example weight\n",
        "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
        "        # return float(weighted_score)\n",
        "\n",
        "        return float(similarity_score) # Currently returns only embedding similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error calculating match score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "# Streamlit App Title and Description\n",
        "st.title(\"AI-Powered Resume Scanner\")\n",
        "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
        "\n",
        "# Add explanation for extraction and scoring using st.markdown\n",
        "st.markdown(\"**How it works:**\")\n",
        "st.markdown(\"1.  Upload a text file resume and enter a job description.\")\n",
        "st.markdown(\"2.  The application preprocesses the text (lowercase, remove punctuation and common words).\")\n",
        "st.markdown(\"3.  It extracts potential skills and experience using pattern matching and general entity recognition.\")\n",
        "st.markdown(\"4.  It calculates a match score based on the overall text similarity of the processed resume text and job description using a text embedding model.\")\n",
        "\n",
        "\n",
        "# File uploader for resume\n",
        "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
        "\n",
        "# Text area for job description\n",
        "job_description_input = st.text_area(\"Enter Job Description\")\n",
        "\n",
        "# Process and display results when file and job description are provided\n",
        "if uploaded_file is not None and job_description_input:\n",
        "    # Read the uploaded file\n",
        "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
        "\n",
        "    st.subheader(\"Processing Resume and Job Description...\")\n",
        "\n",
        "    # Preprocess texts\n",
        "    processed_resume_text = preprocess_text(resume_text)\n",
        "    processed_job_description_text = preprocess_text(job_description_input)\n",
        "\n",
        "    # Extract skills/experience from resume using improved logic\n",
        "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "    # Note: For the job description, you might also want to extract skills\n",
        "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
        "\n",
        "\n",
        "    # Calculate job match score using refined function\n",
        "    # Pass extracted skills if you plan to use them in the matching logic later\n",
        "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
        "\n",
        "\n",
        "    st.subheader(\"Results:\")\n",
        "\n",
        "    # Display extracted information clearly\n",
        "    st.write(\"### Extracted Information:\")\n",
        "    st.write(\"**Skills (based on patterns and entities):**\")\n",
        "    if extracted_skills:\n",
        "        st.write(\", \".join(extracted_skills))\n",
        "    else:\n",
        "        st.write(\"No specific skills found based on current patterns.\")\n",
        "\n",
        "    st.write(\"**Experience (based on patterns and entities):**\")\n",
        "    if extracted_experience:\n",
        "        st.write(\", \".join(extracted_experience))\n",
        "    else:\n",
        "        st.write(\"No specific experience details found based on current patterns.\")\n",
        "\n",
        "\n",
        "    # Display job match score\n",
        "    st.write(\"### Job Match Score:\")\n",
        "    st.write(f\"{match_score:.2f}\")\n",
        "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
        "\n",
        "\n",
        "elif uploaded_file is None and job_description_input:\n",
        "    st.info(\"Please upload a resume file.\")\n",
        "elif uploaded_file is not None and not job_description_input:\n",
        "     st.info(\"Please enter a job description.\")\n",
        "elif uploaded_file is None and not job_description_input:\n",
        "     st.info(\"Please upload a resume file and enter a job description.\")\n",
        "\"\"\"\n",
        "\n",
        "# Create a dummy requirements.txt file content\n",
        "requirements_content = \"\"\"\n",
        "streamlit\n",
        "pandas\n",
        "spacy\n",
        "sentence-transformers\n",
        "scikit-learn\n",
        "nltk\n",
        "# Add specific spaCy model as a requirement for easier deployment setup\n",
        "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "# In a real scenario, you would save these strings to files:\n",
        "# with open(\"app.py\", \"w\") as f:\n",
        "#     f.write(app_code)\n",
        "#\n",
        "# with open(\"requirements.txt\", \"w\") as f:\n",
        "#     f.write(requirements_content)\n",
        "\n",
        "print(\"Updated dummy app.py and requirements.txt content created.\")\n",
        "print(\"\\n--- app.py content ---\")\n",
        "print(app_code)\n",
        "print(\"\\n--- requirements.txt content ---\")\n",
        "print(requirements_content)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated dummy app.py and requirements.txt content created.\n",
            "\n",
            "--- app.py content ---\n",
            "\n",
            "import streamlit as st\n",
            "import pandas as pd\n",
            "import spacy\n",
            "from spacy.matcher import Matcher\n",
            "from sentence_transformers import SentenceTransformer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "import string\n",
            "import nltk\n",
            "from nltk.corpus import stopwords\n",
            "import sys\n",
            "import os\n",
            "import re # Import re for regular expressions\n",
            "\n",
            "# Define model paths\n",
            "SPACY_MODEL = 'en_core_web_lg'\n",
            "SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'\n",
            "\n",
            "# Download necessary NLTK data if not already downloaded\n",
            "try:\n",
            "    nltk.data.find('corpora/stopwords')\n",
            "except LookupError:\n",
            "    st.write(\"NLTK stopwords not found. Downloading...\")\n",
            "    try:\n",
            "        nltk.download('stopwords')\n",
            "        st.write(\"NLTK stopwords downloaded successfully.\")\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error downloading NLTK stopwords: {e}\")\n",
            "        st.stop()\n",
            "\n",
            "# Load spaCy model\n",
            "try:\n",
            "    nlp = spacy.load(SPACY_MODEL)\n",
            "except OSError:\n",
            "    st.write(f\"SpaCy model '{SPACY_MODEL}' not found. Downloading...\")\n",
            "    try:\n",
            "        # In a real deployment, ensure `python -m spacy download en_core_web_lg`\n",
            "        # runs during the build process or use a setup script.\n",
            "        st.error(f\"SpaCy model '{SPACY_MODEL}' not found after initial check. Ensure '{SPACY_MODEL}' is installed and linked correctly in the deployment environment.\")\n",
            "        st.stop()\n",
            "    except Exception as e:\n",
            "        st.error(f\"Failed to load SpaCy model after potential download attempt: {e}\")\n",
            "        st.stop()\n",
            "\n",
            "# Initialize SpaCy Matcher\n",
            "matcher = Matcher(nlp.vocab)\n",
            "\n",
            "# Add patterns for technical skills (example patterns - needs extensive expansion)\n",
            "# This is a basic set, real-world would need many more patterns.\n",
            "skill_patterns = [\n",
            "    [{\"LOWER\": \"python\"}],\n",
            "    [{\"LOWER\": \"data\"}, {\"LOWER\": \"analysis\"}],\n",
            "    [{\"LOWER\": \"machine\"}, {\"LOWER\": \"learning\"}],\n",
            "    [{\"LOWER\": \"sql\"}],\n",
            "    [{\"LOWER\": \"cloud\"}, {\"LOWER\": \"computing\"}],\n",
            "    [{\"LOWER\": \"java\"}],\n",
            "    [{\"LOWER\": \"spring\"}, {\"LOWER\": \"boot\"}],\n",
            "    [{\"LOWER\": \"microservices\"}],\n",
            "    [{\"LOWER\": \"docker\"}],\n",
            "    [{\"LOWER\": \"kubernetes\"}],\n",
            "    [{\"LOWER\": \"javascript\"}],\n",
            "    [{\"LOWER\": \"react\"}],\n",
            "    [{\"LOWER\": \"node\"}, {\"LOWER\": \"js\"}],\n",
            "    [{\"LOWER\": \"aws\"}],\n",
            "    [{\"LOWER\": \"agile\"}, {\"LOWER\": \"methodologies\"}],\n",
            "    [{\"LOWER\": \"c++\"}],\n",
            "    [{\"LOWER\": \"embedded\"}, {\"LOWER\": \"systems\"}],\n",
            "    [{\"LOWER\": \"rtos\"}],\n",
            "    [{\"LOWER\": \"hardware\"}, {\"LOWER\": \"design\"}],\n",
            "    [{\"LOWER\": \"project\"}, {\"LOWER\": \"management\"}],\n",
            "    [{\"LOWER\": \"stakeholder\"}, {\"LOWER\": \"management\"}],\n",
            "    [{\"LOWER\": \"risk\"}, {\"LOWER\": \"assessment\"}],\n",
            "    [{\"LOWER\": \"budgeting\"}]\n",
            "]\n",
            "\n",
            "matcher.add(\"SKILL\", skill_patterns)\n",
            "\n",
            "# Define regex patterns for experience (example patterns - needs extensive expansion)\n",
            "# This is a basic set, real-world would need many more patterns.\n",
            "# Example: look for titles like \"Software Engineer\", \"Data Scientist\", \"Project Manager\"\n",
            "# and potentially associated companies. Regex can be complex for this.\n",
            "# A simple regex to find potential job titles followed by company-like words\n",
            "experience_patterns_regex = [\n",
            "    r\"(data scientist|software engineer|project manager|frontend developer|embedded software engineer)\\s+.*?(inc|ltd|co|group|partners)\\.?\",\n",
            "    r\"(data analyst)\\s+.*?(solutions)\\.?\"\n",
            "]\n",
            "\n",
            "\n",
            "# Load sentence transformer model\n",
            "try:\n",
            "    model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)\n",
            "except Exception as e:\n",
            "    st.error(f\"Failed to load Sentence Transformer model: {e}\")\n",
            "    st.stop()\n",
            "\n",
            "\n",
            "# Define text preprocessing function (from previous step)\n",
            "stop_words = set(stopwords.words('english'))\n",
            "def preprocess_text(text):\n",
            "    text = text.lower()\n",
            "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
            "    tokens = text.split()\n",
            "    processed_tokens = [word for word in tokens if word and word not in stop_words]\n",
            "    return \" \".join(processed_tokens)\n",
            "\n",
            "# Define skill and experience extraction function (Improved version)\n",
            "def extract_skills_experience_improved(text, nlp_model, matcher, experience_patterns_regex):\n",
            "    doc = nlp_model(text)\n",
            "    extracted_skills = set() # Use a set to avoid duplicates\n",
            "    extracted_experience = set()\n",
            "\n",
            "    # Use SpaCy Matcher for predefined skill patterns\n",
            "    matches = matcher(doc)\n",
            "    for match_id, start, end in matches:\n",
            "        span = doc[start:end]\n",
            "        extracted_skills.add(span.text)\n",
            "\n",
            "    # Use Regex for experience patterns\n",
            "    for pattern in experience_patterns_regex:\n",
            "        for match in re.finditer(pattern, text):\n",
            "             extracted_experience.add(match.group(0).strip())\n",
            "\n",
            "\n",
            "    # Optional: Also add relevant NER entities that might be skills/experience components\n",
            "    # Be more selective with NER entities if using pattern matching\n",
            "    # for ent in doc.ents:\n",
            "    #      # Add only relevant entities if not covered by patterns, e.g., specific company names (ORG)\n",
            "    #      if ent.label_ in ['ORG'] and ent.text not in extracted_experience:\n",
            "    #          extracted_experience.add(ent.text)\n",
            "    #      # Can add other entity types if they reliably represent skills or roles\n",
            "\n",
            "    return list(extracted_skills), list(extracted_experience)\n",
            "\n",
            "\n",
            "# Define job matching function (refined - ready for weighted similarity if needed)\n",
            "def get_match_score_refined(resume_text, job_description_text, model, resume_skills, job_desc_skills=[]):\n",
            "    if not resume_text or not job_description_text:\n",
            "        return 0.0\n",
            "\n",
            "    try:\n",
            "        # Base similarity on processed text embedding\n",
            "        resume_embedding = model.encode(resume_text)\n",
            "        job_description_embedding = model.encode(job_description_text)\n",
            "\n",
            "        resume_embedding_reshaped = resume_embedding.reshape(1, -1)\n",
            "        job_description_embedding_reshaped = job_description_embedding.reshape(1, -1)\n",
            "\n",
            "        similarity_score = cosine_similarity(resume_embedding_reshaped, job_description_embedding_reshaped)[0][0]\n",
            "\n",
            "        # Future refinement: Incorporate extracted skills for a weighted score\n",
            "        # Example (conceptual - requires defined weights and skill matching logic):\n",
            "        # common_skills = set(resume_skills).intersection(set(job_desc_skills))\n",
            "        # skill_weight = 0.3 # Example weight\n",
            "        # embedding_weight = 0.7 # Example weight\n",
            "        # weighted_score = (embedding_weight * similarity_score) + (skill_weight * (len(common_skills) / max(len(resume_skills), 1)))\n",
            "        # return float(weighted_score)\n",
            "\n",
            "        return float(similarity_score) # Currently returns only embedding similarity\n",
            "\n",
            "    except Exception as e:\n",
            "        st.error(f\"Error calculating match score: {e}\")\n",
            "        return 0.0\n",
            "\n",
            "\n",
            "# Streamlit App Title and Description\n",
            "st.title(\"AI-Powered Resume Scanner\")\n",
            "st.write(\"Upload your resume and enter a job description to see how well they match and extract key information.\")\n",
            "\n",
            "# Add explanation for extraction and scoring using st.markdown\n",
            "st.markdown(\"**How it works:**\")\n",
            "st.markdown(\"1.  Upload a text file resume and enter a job description.\")\n",
            "st.markdown(\"2.  The application preprocesses the text (lowercase, remove punctuation and common words).\")\n",
            "st.markdown(\"3.  It extracts potential skills and experience using pattern matching and general entity recognition.\")\n",
            "st.markdown(\"4.  It calculates a match score based on the overall text similarity of the processed resume text and job description using a text embedding model.\")\n",
            "\n",
            "\n",
            "# File uploader for resume\n",
            "uploaded_file = st.file_uploader(\"Upload your Resume (Text file)\", type=[\"txt\"])\n",
            "\n",
            "# Text area for job description\n",
            "job_description_input = st.text_area(\"Enter Job Description\")\n",
            "\n",
            "# Process and display results when file and job description are provided\n",
            "if uploaded_file is not None and job_description_input:\n",
            "    # Read the uploaded file\n",
            "    resume_text = uploaded_file.getvalue().decode(\"utf-8\")\n",
            "\n",
            "    st.subheader(\"Processing Resume and Job Description...\")\n",
            "\n",
            "    # Preprocess texts\n",
            "    processed_resume_text = preprocess_text(resume_text)\n",
            "    processed_job_description_text = preprocess_text(job_description_input)\n",
            "\n",
            "    # Extract skills/experience from resume using improved logic\n",
            "    extracted_skills, extracted_experience = extract_skills_experience_improved(processed_resume_text, nlp, matcher, experience_patterns_regex)\n",
            "\n",
            "    # Note: For the job description, you might also want to extract skills\n",
            "    # job_desc_extracted_skills, _ = extract_skills_experience_improved(processed_job_description_text, nlp, matcher, experience_patterns_regex)\n",
            "\n",
            "\n",
            "    # Calculate job match score using refined function\n",
            "    # Pass extracted skills if you plan to use them in the matching logic later\n",
            "    match_score = get_match_score_refined(processed_resume_text, processed_job_description_text, model, extracted_skills)\n",
            "\n",
            "\n",
            "    st.subheader(\"Results:\")\n",
            "\n",
            "    # Display extracted information clearly\n",
            "    st.write(\"### Extracted Information:\")\n",
            "    st.write(\"**Skills (based on patterns and entities):**\")\n",
            "    if extracted_skills:\n",
            "        st.write(\", \".join(extracted_skills))\n",
            "    else:\n",
            "        st.write(\"No specific skills found based on current patterns.\")\n",
            "\n",
            "    st.write(\"**Experience (based on patterns and entities):**\")\n",
            "    if extracted_experience:\n",
            "        st.write(\", \".join(extracted_experience))\n",
            "    else:\n",
            "        st.write(\"No specific experience details found based on current patterns.\")\n",
            "\n",
            "\n",
            "    # Display job match score\n",
            "    st.write(\"### Job Match Score:\")\n",
            "    st.write(f\"{match_score:.2f}\")\n",
            "    st.write(\"_This score is currently based on the overall text similarity between your processed resume and the job description._\")\n",
            "\n",
            "\n",
            "elif uploaded_file is None and job_description_input:\n",
            "    st.info(\"Please upload a resume file.\")\n",
            "elif uploaded_file is not None and not job_description_input:\n",
            "     st.info(\"Please enter a job description.\")\n",
            "elif uploaded_file is None and not job_description_input:\n",
            "     st.info(\"Please upload a resume file and enter a job description.\")\n",
            "\n",
            "\n",
            "--- requirements.txt content ---\n",
            "\n",
            "streamlit\n",
            "pandas\n",
            "spacy\n",
            "sentence-transformers\n",
            "scikit-learn\n",
            "nltk\n",
            "# Add specific spaCy model as a requirement for easier deployment setup\n",
            "en_core_web_lg@https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.0/en_core_web_lg-3.7.0.tar.gz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca815a7d"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Scraping LinkedIn profiles directly failed due to LinkedIn's anti-scraping measures, necessitating the use of synthetic data for subsequent steps.\n",
        "*   Preprocessing steps including lowercasing, punctuation removal, tokenization, and stop word removal were successfully applied to the text data.\n",
        "*   Initial skill and experience extraction using SpaCy's general Named Entity Recognition (NER) was not specific enough for identifying technical skills and detailed experience.\n",
        "*   Job matching using Sentence Transformer embeddings and cosine similarity showed intuitively reasonable scores with clean synthetic data, indicating its potential but also highlighting its reliance on accurate input data.\n",
        "*   Refinement involved implementing SpaCy's `Matcher` and regular expressions for potentially better skill and experience extraction, although the pattern sets used were basic examples.\n",
        "*   The final Streamlit application code (`app.py`) includes necessary components for UI, preprocessing, extraction, and matching, with instructions for deployment via `requirements.txt`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Enhance skill and experience extraction by creating a comprehensive and domain-specific set of patterns for SpaCy's `Matcher` and refining regex patterns for experience details. Consider exploring more advanced techniques like training custom NER models or using transformer-based models for token classification specifically for skills and roles.\n",
        "*   Improve the job matching logic by incorporating the extracted skills and experience into a weighted similarity score, giving more importance to matching specific required skills mentioned in the job description.\n",
        "\n",
        "### AI-Powered Resume Scanner Capabilities (as implemented in the `app.py` placeholder)\n",
        "\n",
        "*   **Resume and Job Description Upload/Input**: Allows users to provide their resume as a text file and enter a job description via a text area.\n",
        "*   **Text Preprocessing**: Cleans the input text by lowercasing, removing punctuation, and removing common English stop words.\n",
        "*   **Skill and Experience Extraction**: Extracts potential skills and experience from the processed resume text using predefined SpaCy `Matcher` patterns and regular expressions.\n",
        "*   **Job Matching**: Calculates a job match score based on the cosine similarity between the text embeddings of the processed resume and job description using a pre-trained Sentence Transformer model.\n",
        "*   **Results Display**: Presents the extracted skills and experience and the calculated job match score to the user in the Streamlit interface.\n",
        "\n",
        "**Note**: The current implementation is a foundational example. For a production-ready application, significant effort would be needed to build a comprehensive skill/experience extraction model (potentially through data labeling and training), refine the matching algorithm (e.g., weighted scoring, keyword matching), handle various resume formats (PDF, DOCX), and implement robust error handling and user feedback mechanisms."
      ]
    }
  ]
}